# web_app.py
# -*- coding: utf-8 -*-
"""
AI_NovelGenerator Gradio Web Interface
åŸºäºåŸæœ‰GUIåŠŸèƒ½åˆ›å»ºçš„Webç•Œé¢ç‰ˆæœ¬
"""

import gradio as gr
import os
import json
import threading
import traceback
from typing import Optional, Tuple, Dict, Any

# å¯¼å…¥åŸæœ‰çš„æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
from config_manager import load_config, save_config, test_llm_config, test_embedding_config
from novel_generator import (
    Novel_architecture_generate,
    Chapter_blueprint_generate,
    generate_chapter_draft,
    finalize_chapter,
    import_knowledge_file,
    clear_vector_store
)
from consistency_checker import check_consistency
from utils import read_file, save_string_to_txt, clear_file_content
from llm_adapters import create_llm_adapter
from embedding_adapters import create_embedding_adapter

class NovelGeneratorWebApp:
    """AIå°è¯´ç”Ÿæˆå™¨Webåº”ç”¨ç±»"""

    def __init__(self):
        self.config_file = "config.json"
        self.loaded_config = load_config(self.config_file)

        # åˆå§‹åŒ–é»˜è®¤é…ç½®
        self.init_default_config()

        # çŠ¶æ€å˜é‡
        self.current_chapter_num = 1
        self.generation_in_progress = False

    def init_default_config(self):
        """åˆå§‹åŒ–é»˜è®¤é…ç½®"""
        if self.loaded_config:
            self.last_llm = self.loaded_config.get("last_interface_format", "OpenAI")
            self.last_embedding = self.loaded_config.get("last_embedding_interface_format", "OpenAI")
        else:
            self.last_llm = "OpenAI"
            self.last_embedding = "OpenAI"

    def log_message(self, message: str) -> str:
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        import datetime
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        return f"[{timestamp}] {message}\n"

    def update_params_overview(self, topic, genre, num_chapters, word_number):
        """æ›´æ–°å‚æ•°æ¦‚è§ˆæ˜¾ç¤º"""
        topic_display = topic if topic.strip() else "æœªè®¾ç½®"
        if len(topic_display) > 50:
            topic_display = topic_display[:50] + "..."

        # ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥é¿å…f-stringä¸­çš„å¤æ‚JavaScript
        html_content = """
        <div style="background: #f8f9fa; border-radius: 12px; padding: 1.5rem; border-left: 4px solid #667eea;">
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin-bottom: 1rem;">
                <div>
                    <div style="font-size: 0.85rem; color: #666; margin-bottom: 0.25rem;">ğŸ“– å°è¯´ä¸»é¢˜</div>
                    <div style="font-size: 0.95rem; color: #333; font-weight: 500;">""" + topic_display + """</div>
                </div>
                <div>
                    <div style="font-size: 0.85rem; color: #666; margin-bottom: 0.25rem;">ğŸ“š ç±»å‹</div>
                    <div style="font-size: 0.95rem; color: #333; font-weight: 500;">""" + str(genre) + """</div>
                </div>
                <div>
                    <div style="font-size: 0.85rem; color: #666; margin-bottom: 0.25rem;">ğŸ“‘ ç« èŠ‚æ•°</div>
                    <div style="font-size: 0.95rem; color: #333; font-weight: 500;">""" + str(num_chapters) + """ç« </div>
                </div>
                <div>
                    <div style="font-size: 0.85rem; color: #666; margin-bottom: 0.25rem;">ğŸ“ æ¯ç« å­—æ•°</div>
                    <div style="font-size: 0.95rem; color: #333; font-weight: 500;">""" + str(word_number) + """å­—</div>
                </div>
            </div>
        </div>
        """
        return html_content

    def get_llm_config_from_form(self, interface_format, api_key, base_url, model_name,
                                temperature, max_tokens, timeout):
        """ä»è¡¨å•è·å–LLMé…ç½®"""
        return {
            "interface_format": interface_format,
            "api_key": api_key,
            "base_url": base_url,
            "model_name": model_name,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "timeout": timeout
        }

    def get_embedding_config_from_form(self, interface_format, api_key, base_url,
                                     model_name, retrieval_k):
        """ä»è¡¨å•è·å–Embeddingé…ç½®"""
        return {
            "interface_format": interface_format,
            "api_key": api_key,
            "base_url": base_url,
            "model_name": model_name,
            "retrieval_k": retrieval_k
        }

    def save_config_to_file(self, llm_config, embedding_config, novel_params):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            # åˆ†ç¦»å…¨å±€é…ç½®å’Œå°è¯´ç‰¹å®šé…ç½®
            global_config_data = {
                "last_interface_format": llm_config["interface_format"],
                "last_embedding_interface_format": embedding_config["interface_format"],
                "llm_configs": {
                    llm_config["interface_format"]: {
                        "api_key": llm_config["api_key"],
                        "base_url": llm_config["base_url"],
                        "model_name": llm_config["model_name"],
                        "temperature": llm_config["temperature"],
                        "max_tokens": llm_config["max_tokens"],
                        "timeout": llm_config["timeout"]
                    }
                },
                "embedding_configs": {
                    embedding_config["interface_format"]: {
                        "api_key": embedding_config["api_key"],
                        "base_url": embedding_config["base_url"],
                        "model_name": embedding_config["model_name"],
                        "retrieval_k": embedding_config["retrieval_k"]
                    }
                }
            }

            # ä¿å­˜å…¨å±€é…ç½®ï¼ˆä¸åŒ…å«å°è¯´å‚æ•°ï¼‰
            success = save_config(global_config_data, self.config_file)
            if not success:
                return "âŒ å…¨å±€é…ç½®ä¿å­˜å¤±è´¥ï¼"

            # ä¿å­˜å°è¯´ç‰¹å®šé…ç½®
            novel_config_result = self.save_novel_config(novel_params)

            if success:
                self.loaded_config = global_config_data
                return f"âœ… é…ç½®ä¿å­˜æˆåŠŸï¼{novel_config_result}"
            else:
                return "âŒ é…ç½®ä¿å­˜å¤±è´¥ï¼"
        except Exception as e:
            return f"âŒ ä¿å­˜é…ç½®æ—¶å‡ºé”™: {str(e)}"

    def save_novel_config(self, novel_params):
        """ä¿å­˜å°è¯´ç‰¹å®šé…ç½®åˆ°å°è¯´ç›®å½•ä¸‹"""
        try:
            filepath = novel_params.get("filepath", "").strip()
            if not filepath:
                return " å°è¯´å‚æ•°æœªä¿å­˜ï¼ˆæœªè®¾ç½®ä¿å­˜è·¯å¾„ï¼‰"

            # ç¡®ä¿å°è¯´ç›®å½•å­˜åœ¨
            os.makedirs(filepath, exist_ok=True)

            # å°è¯´é…ç½®æ–‡ä»¶è·¯å¾„
            novel_config_file = os.path.join(filepath, "novel_config.json")

            # ä¿å­˜å°è¯´å‚æ•°
            success = save_config(novel_params, novel_config_file)
            if success:
                return " å°è¯´å‚æ•°å·²ä¿å­˜åˆ°é¡¹ç›®ç›®å½•"
            else:
                return " å°è¯´å‚æ•°ä¿å­˜å¤±è´¥"
        except Exception as e:
            return f" å°è¯´å‚æ•°ä¿å­˜å‡ºé”™: {str(e)}"

    def load_novel_config(self, filepath):
        """ä»å°è¯´ç›®å½•åŠ è½½å°è¯´ç‰¹å®šé…ç½®"""
        try:
            if not filepath or not filepath.strip():
                return {}

            novel_config_file = os.path.join(filepath.strip(), "novel_config.json")
            if not os.path.exists(novel_config_file):
                return {}

            return load_config(novel_config_file)
        except Exception as e:
            print(f"åŠ è½½å°è¯´é…ç½®å‡ºé”™: {str(e)}")
            return {}

    def load_config_from_file(self, filepath=None):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            cfg = load_config(self.config_file)
            if not cfg:
                return None, "æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶"

            # æå–LLMé…ç½®
            last_llm = cfg.get("last_interface_format", "OpenAI")
            llm_configs = cfg.get("llm_configs", {})
            llm_config = llm_configs.get(last_llm, {})

            # æå–Embeddingé…ç½®
            last_embedding = cfg.get("last_embedding_interface_format", "OpenAI")
            embedding_configs = cfg.get("embedding_configs", {})
            embedding_config = embedding_configs.get(last_embedding, {})

            # åŠ è½½å°è¯´ç‰¹å®šé…ç½®ï¼ˆå¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾„ï¼‰
            novel_params = {}
            if filepath:
                novel_params = self.load_novel_config(filepath)
            else:
                # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šä»å…¨å±€é…ç½®ä¸­è¯»å–
                novel_params = cfg.get("other_params", {})

            return {
                "llm_interface": last_llm,
                "llm_api_key": llm_config.get("api_key", ""),
                "llm_base_url": llm_config.get("base_url", "https://api.openai.com/v1"),
                "llm_model": llm_config.get("model_name", "gpt-4o-mini"),
                "temperature": llm_config.get("temperature", 0.7),
                "max_tokens": llm_config.get("max_tokens", 8192),
                "timeout": llm_config.get("timeout", 600),
                "embedding_interface": last_embedding,
                "embedding_api_key": embedding_config.get("api_key", ""),
                "embedding_base_url": embedding_config.get("base_url", "https://api.openai.com/v1"),
                "embedding_model": embedding_config.get("model_name", "text-embedding-ada-002"),
                "retrieval_k": embedding_config.get("retrieval_k", 4),
                "topic": novel_params.get("topic", ""),
                "genre": novel_params.get("genre", "ç„å¹»"),
                "num_chapters": novel_params.get("num_chapters", 10),
                "word_number": novel_params.get("word_number", 3000),
                "filepath": novel_params.get("filepath", ""),
                "user_guidance": novel_params.get("user_guidance", ""),
                "characters_involved": novel_params.get("characters_involved", ""),
                "key_items": novel_params.get("key_items", ""),
                "scene_location": novel_params.get("scene_location", ""),
                "time_constraint": novel_params.get("time_constraint", "")
            }, "âœ… é…ç½®åŠ è½½æˆåŠŸï¼"
        except Exception as e:
            return None, f"âŒ åŠ è½½é…ç½®æ—¶å‡ºé”™: {str(e)}"

# åˆ›å»ºå…¨å±€åº”ç”¨å®ä¾‹
app = NovelGeneratorWebApp()

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""

    # å®šä¹‰LLMæ¥å£é€‰é¡¹
    llm_interfaces = ["OpenAI", "DeepSeek", "Azure OpenAI", "Azure AI", "Ollama",
                     "ML Studio", "Gemini", "é˜¿é‡Œäº‘ç™¾ç‚¼", "ç«å±±å¼•æ“", "ç¡…åŸºæµåŠ¨"]

    # å®šä¹‰ç±»å‹é€‰é¡¹ - æ”¯æŒè‡ªå®šä¹‰è¾“å…¥
    genres = [
        "ç„å¹»", "ä»™ä¾ ", "éƒ½å¸‚", "å†å²", "ç§‘å¹»", "å†›äº‹", "æ¸¸æˆ", "ä½“è‚²", "æ‚¬ç–‘",
        "è¨€æƒ…", "æ­¦ä¾ ", "å¥‡å¹»", "æ¨ç†", "ææ€–", "é’æ˜¥", "èŒåœº", "ç©¿è¶Š", "é‡ç”Ÿ",
        "æœ«ä¸–", "æœºç”²", "æ˜Ÿé™…", "ä¿®çœŸ", "çµå¼‚", "æ ¡å›­", "å¤è¨€", "ç°è¨€", "è€½ç¾",
        "ç™¾åˆ", "åŒäºº", "è½»å°è¯´", "ç½‘æ¸¸", "ç«æŠ€", "ç¾é£Ÿ", "åŒ»ç–—", "å¾‹æ”¿", "å…¶ä»–"
    ]

    # è‡ªåŠ¨åŠ è½½å·²ä¿å­˜çš„é…ç½®
    config_data, config_message = app.load_config_from_file()
    if config_data:
        print(f"âœ… è‡ªåŠ¨åŠ è½½é…ç½®æˆåŠŸ: {config_message}")
        # ä½¿ç”¨åŠ è½½çš„é…ç½®ä½œä¸ºé»˜è®¤å€¼
        default_llm_interface = config_data["llm_interface"]
        default_llm_api_key = config_data["llm_api_key"]
        default_llm_base_url = config_data["llm_base_url"]
        default_llm_model = config_data["llm_model"]
        default_temperature = config_data["temperature"]
        default_max_tokens = config_data["max_tokens"]
        default_timeout = config_data["timeout"]
        default_embedding_interface = config_data["embedding_interface"]
        default_embedding_api_key = config_data["embedding_api_key"]
        default_embedding_base_url = config_data["embedding_base_url"]
        default_embedding_model = config_data["embedding_model"]
        default_retrieval_k = config_data["retrieval_k"]
        default_topic = config_data["topic"]
        default_genre = config_data["genre"]
        default_num_chapters = config_data["num_chapters"]
        default_word_number = config_data["word_number"]
        default_filepath = config_data["filepath"]
        default_user_guidance = config_data["user_guidance"]
        default_characters_involved = config_data["characters_involved"]
        default_key_items = config_data["key_items"]
        default_scene_location = config_data["scene_location"]
        default_time_constraint = config_data["time_constraint"]
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼: {config_message}")
        # ä½¿ç”¨é»˜è®¤å€¼
        default_llm_interface = "OpenAI"
        default_llm_api_key = ""
        default_llm_base_url = "https://api.openai.com/v1"
        default_llm_model = "gpt-4o-mini"
        default_temperature = 0.7
        default_max_tokens = 8192
        default_timeout = 600
        default_embedding_interface = "OpenAI"
        default_embedding_api_key = ""
        default_embedding_base_url = "https://api.openai.com/v1"
        default_embedding_model = "text-embedding-ada-002"
        default_retrieval_k = 4
        default_topic = ""
        default_genre = "ç„å¹»"
        default_num_chapters = 10
        default_word_number = 3000
        default_filepath = ""
        default_user_guidance = ""
        default_characters_involved = ""
        default_key_items = ""
        default_scene_location = ""
        default_time_constraint = ""

    # åˆ›å»ºè‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    /* å…¨å±€æ ·å¼ - å¼ºåˆ¶ç»Ÿä¸€å®½åº¦ */
    .gradio-container {
        max-width: 1400px !important;
        width: 100% !important;
        margin: 0 auto !important;
        padding: 1rem !important;
        box-sizing: border-box !important;
    }

    /* ç»Ÿä¸€çš„é¡µé¢å®¹å™¨ - æ‰€æœ‰å†…å®¹çš„çˆ¶å®¹å™¨ */
    .page-container {
        max-width: 1400px !important;
        width: 100% !important;
        margin: 0 auto !important;
        padding: 0 !important;
        box-sizing: border-box !important;
    }

    /* å¼ºåˆ¶æ‰€æœ‰æ ‡ç­¾é¡µå†…å®¹å®½åº¦ä¸€è‡´ */
    .gradio-tabitem {
        max-width: 1400px !important;
        width: 100% !important;
        padding: 0 !important;
        margin: 0 auto !important;
        box-sizing: border-box !important;
    }

    /* å¼ºåˆ¶æ‰€æœ‰è¡Œå’Œåˆ—çš„å®½åº¦ä¸€è‡´ */
    .gradio-row {
        max-width: 100% !important;
        width: 100% !important;
        margin: 0 !important;
    }

    .gradio-column {
        width: 100% !important;
    }

    /* å¼ºåˆ¶æ‰€æœ‰å†…å®¹å…ƒç´ å®½åº¦ä¸€è‡´ */
    .gradio-tabs {
        max-width: 1400px !important;
        width: 100% !important;
        margin: 0 auto !important;
    }

    /* æ ‡é¢˜æ ·å¼ */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        width: 100% !important;
        box-sizing: border-box !important;
    }

    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }

    .main-subtitle {
        font-size: 1.2rem;
        opacity: 0.9;
        margin-bottom: 1rem;
    }

    /* å¡ç‰‡æ ·å¼ */
    .feature-card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 16px rgba(0,0,0,0.1);
        border: 1px solid #e1e5e9;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
        width: 100% !important;
        box-sizing: border-box !important;
    }

    .feature-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 24px rgba(0,0,0,0.15);
    }

    /* æŒ‰é’®æ ·å¼ */
    .primary-button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 12px 24px !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
    }

    .primary-button:hover {
        transform: translateY(-1px) !important;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4) !important;
    }

    /* æ ‡ç­¾é¡µæ ·å¼ */
    .tab-nav {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 0.5rem;
        margin-bottom: 1rem;
    }

    /* æ—¥å¿—çª—å£æ ·å¼ */
    .log-container {
        background: #1e1e1e;
        color: #00ff00;
        font-family: 'Courier New', monospace;
        border-radius: 8px;
        padding: 1rem;
    }

    /* å¯æ»šåŠ¨æ–‡æœ¬æ¡†æ ·å¼ - å¼ºåˆ¶æ˜¾ç¤ºæ»šåŠ¨æ¡ */
    .scrollable-textbox textarea {
        overflow-y: scroll !important;
        scrollbar-width: thin !important;
        scrollbar-color: #888 #f1f1f1 !important;
    }

    /* Webkitæµè§ˆå™¨æ»šåŠ¨æ¡æ ·å¼ */
    .scrollable-textbox textarea::-webkit-scrollbar {
        width: 8px !important;
    }

    .scrollable-textbox textarea::-webkit-scrollbar-track {
        background: #f1f1f1 !important;
        border-radius: 4px !important;
    }

    .scrollable-textbox textarea::-webkit-scrollbar-thumb {
        background: #888 !important;
        border-radius: 4px !important;
    }

    .scrollable-textbox textarea::-webkit-scrollbar-thumb:hover {
        background: #555 !important;
    }

    /* ç¡®ä¿æ–‡æœ¬æ¡†æœ‰å›ºå®šé«˜åº¦ä»¥è§¦å‘æ»šåŠ¨æ¡ */
    .scrollable-textbox {
        height: 400px !important;
        min-height: 400px !important;
    }

    .scrollable-textbox textarea {
        height: 100% !important;
        min-height: 400px !important;
        resize: vertical !important;
    }

    /* é…ç½®åŒºåŸŸæ ·å¼ */
    .config-section {
        background: #f8f9fa;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid #667eea;
        width: 100% !important;
        box-sizing: border-box !important;
    }

    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }

    .status-success { background-color: #28a745; }
    .status-warning { background-color: #ffc107; }
    .status-error { background-color: #dc3545; }

    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .main-title { font-size: 2rem; }
        .main-subtitle { font-size: 1rem; }
        .feature-card { margin: 0.5rem 0; padding: 1rem; }
    }
    """

    with gr.Blocks(
        title="AIå°è¯´ç”Ÿæˆå™¨ - æ™ºèƒ½åˆ›ä½œå¹³å°",
        theme=gr.themes.Soft(),
        css=custom_css
    ) as demo:

        # ç»Ÿä¸€çš„é¡µé¢å®¹å™¨ - åŒ…å«æ‰€æœ‰å†…å®¹
        with gr.Column(elem_classes=["page-container"]):
            # Landingé¡µé¢å¤´éƒ¨
            gr.HTML("""
            <div class="main-header">
                <div class="main-title">ğŸ¯ AIå°è¯´ç”Ÿæˆå™¨</div>
                <div class="main-subtitle">åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½å°è¯´åˆ›ä½œå¹³å°</div>
                <div style="margin-top: 1rem;">
                    <span style="background: rgba(255,255,255,0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem;">
                        âœ¨ æ™ºèƒ½æ¶æ„ç”Ÿæˆ
                    </span>
                    <span style="background: rgba(255,255,255,0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem;">
                        ğŸ“š ç« èŠ‚è“å›¾è§„åˆ’
                    </span>
                    <span style="background: rgba(255,255,255,0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem;">
                        ğŸ” æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢
                    </span>
                </div>
            </div>
            """)

            # ä¸»è¦çŠ¶æ€å˜é‡
            log_state = gr.State("")

            with gr.Tabs() as tabs:
                # Tab 0: æ¬¢è¿é¡µé¢
                with gr.Tab("ğŸ  æ¬¢è¿", id="welcome"):
                    with gr.Row():
                        with gr.Column(scale=2):
                            gr.HTML("""
                            <div class="feature-card">
                                <h2>ğŸš€ å¿«é€Ÿå¼€å§‹</h2>
                                <p>æ¬¢è¿ä½¿ç”¨AIå°è¯´ç”Ÿæˆå™¨ï¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¼€å§‹æ‚¨çš„åˆ›ä½œä¹‹æ—…ï¼š</p>
                                <ol style="line-height: 1.8;">
                                    <li><strong>é…ç½®æ¨¡å‹</strong> - å‰å¾€"æ¨¡å‹é…ç½®"é¡µé¢è®¾ç½®æ‚¨çš„AIæ¨¡å‹</li>
                                    <li><strong>è®¾ç½®å‚æ•°</strong> - åœ¨"å°è¯´å‚æ•°"é¡µé¢å¡«å†™å°è¯´åŸºæœ¬ä¿¡æ¯</li>
                                    <li><strong>å¼€å§‹åˆ›ä½œ</strong> - åœ¨"ä¸»è¦åŠŸèƒ½"é¡µé¢æŒ‰æ­¥éª¤ç”Ÿæˆå°è¯´</li>
                                    <li><strong>ç®¡ç†æ–‡ä»¶</strong> - ä½¿ç”¨"æ–‡ä»¶ç®¡ç†"é¡µé¢æŸ¥çœ‹å’Œç¼–è¾‘å†…å®¹</li>
                                </ol>
                            </div>
                            """)

                        with gr.Row():
                            with gr.Column():
                                gr.HTML("""
                                <div class="feature-card">
                                    <h3>âœ¨ æ ¸å¿ƒåŠŸèƒ½</h3>
                                    <ul style="line-height: 1.6;">
                                        <li><strong>æ™ºèƒ½æ¶æ„ç”Ÿæˆ</strong> - AIè‡ªåŠ¨æ„å»ºå°è¯´ä¸–ç•Œè§‚å’Œæƒ…èŠ‚æ¡†æ¶</li>
                                        <li><strong>ç« èŠ‚è“å›¾è§„åˆ’</strong> - è¯¦ç»†çš„ç« èŠ‚å¤§çº²å’Œå‰§æƒ…å®‰æ’</li>
                                        <li><strong>è‰ç¨¿æ™ºèƒ½ç”Ÿæˆ</strong> - åŸºäºä¸Šä¸‹æ–‡çš„ç« èŠ‚å†…å®¹åˆ›ä½œ</li>
                                        <li><strong>ä¸€è‡´æ€§æ£€æŸ¥</strong> - è‡ªåŠ¨æ£€æµ‹å‰§æƒ…é€»è¾‘å’Œè§’è‰²ä¸€è‡´æ€§</li>
                                    </ul>
                                </div>
                                """)

                            with gr.Column():
                                gr.HTML("""
                                <div class="feature-card">
                                    <h3>ğŸ¯ æ”¯æŒçš„æ¨¡å‹</h3>
                                    <ul style="line-height: 1.6;">
                                        <li><strong>OpenAI</strong> - GPT-4, GPT-3.5ç³»åˆ—</li>
                                        <li><strong>Google Gemini</strong> - Gemini Pro, Flashç³»åˆ—</li>
                                        <li><strong>DeepSeek</strong> - DeepSeek Chatç³»åˆ—</li>
                                        <li><strong>ç«å±±å¼•æ“</strong> - è±†åŒ…ç³»åˆ—æ¨¡å‹</li>
                                        <li><strong>å…¶ä»–</strong> - Azure OpenAI, Ollamaç­‰</li>
                                    </ul>
                                </div>
                                """)

                    with gr.Column(scale=1):
                        gr.HTML("""
                        <div class="feature-card">
                            <h3>ğŸ“Š ç³»ç»ŸçŠ¶æ€</h3>
                            <div style="margin: 1rem 0;">
                                <div style="margin: 0.5rem 0;">
                                    <span class="status-indicator status-warning"></span>
                                    <span>é…ç½®çŠ¶æ€: å¾…è®¾ç½®</span>
                                </div>
                                <div style="margin: 0.5rem 0;">
                                    <span class="status-indicator status-warning"></span>
                                    <span>æ¨¡å‹è¿æ¥: æœªæµ‹è¯•</span>
                                </div>
                                <div style="margin: 0.5rem 0;">
                                    <span class="status-indicator status-success"></span>
                                    <span>ç³»ç»ŸçŠ¶æ€: æ­£å¸¸</span>
                                </div>
                            </div>
                        </div>
                        """)

                        gr.HTML("""
                        <div class="feature-card">
                            <h3>ğŸ’¡ ä½¿ç”¨æç¤º</h3>
                            <ul style="line-height: 1.6; font-size: 0.9rem;">
                                <li>é¦–æ¬¡ä½¿ç”¨è¯·å…ˆé…ç½®APIå¯†é’¥</li>
                                <li>å»ºè®®å…ˆæµ‹è¯•æ¨¡å‹è¿æ¥</li>
                                <li>è®¾ç½®åˆé€‚çš„ä¿å­˜è·¯å¾„</li>
                                <li>å¯ä»¥éšæ—¶ç¼–è¾‘ç”Ÿæˆçš„å†…å®¹</li>
                                <li>æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼å¯¼å‡º</li>
                            </ul>
                        </div>
                        """)

                        # å¿«é€Ÿé…ç½®æŒ‰é’®
                        with gr.Row():
                            quick_config_btn = gr.Button("ğŸ”§ å¿«é€Ÿé…ç½®", variant="primary", elem_classes=["primary-button"])
                            quick_start_btn = gr.Button("ğŸš€ å¼€å§‹åˆ›ä½œ", variant="primary", elem_classes=["primary-button"])

                # Tab 1: ä¸»è¦åŠŸèƒ½
                with gr.Tab("ğŸ¤– AIè‡ªåŠ¨åˆ›ä½œ", id="main"):
                    # é¡¹ç›®ç®¡ç†åŒºåŸŸ
                    with gr.Accordion("ğŸ“ å°è¯´é¡¹ç›®ç®¡ç†", open=True):
                        gr.HTML("""
                        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                    color: white; padding: 1rem; border-radius: 12px; margin-bottom: 1rem;
                                    text-align: center;">
                            <h3 style="margin: 0 0 0.5rem 0;">ğŸ¯ å¼€å§‹æ‚¨çš„åˆ›ä½œä¹‹æ—…</h3>
                            <p style="margin: 0; opacity: 0.9; font-size: 0.9rem;">
                                è¯·å…ˆåˆ›å»ºæ–°é¡¹ç›®æˆ–åŠ è½½ç°æœ‰é¡¹ç›®ï¼Œç„¶åå¼€å§‹AIè‡ªåŠ¨åˆ›ä½œ
                            </p>
                        </div>
                        """)

                        with gr.Row():
                            with gr.Column(scale=3):
                                with gr.Row():
                                    project_path_input = gr.Textbox(
                                        label="ğŸ“ é¡¹ç›®è·¯å¾„",
                                        placeholder="ä¾‹å¦‚: /Users/username/novels/æˆ‘çš„å°è¯´",
                                        value=default_filepath,
                                        info="å°è¯´é¡¹ç›®çš„ä¿å­˜ç›®å½•ï¼ˆæ¯ä¸ªå°è¯´ä¸€ä¸ªç‹¬ç«‹ç›®å½•ï¼‰",
                                        scale=4
                                    )
                                    btn_browse_folder = gr.Button(
                                        "ğŸ“‚ æµè§ˆ",
                                        variant="secondary",
                                        size="sm",
                                        scale=1
                                    )
                            with gr.Column(scale=2):
                                with gr.Row():
                                    btn_create_project = gr.Button(
                                        "ğŸ“ åˆ›å»ºæ–°é¡¹ç›®",
                                        variant="primary",
                                        scale=1
                                    )
                                    btn_load_project = gr.Button(
                                        "ğŸ“‚ åŠ è½½é¡¹ç›®",
                                        variant="secondary",
                                        scale=1
                                    )

                        # é¡¹ç›®çŠ¶æ€æ˜¾ç¤º
                        project_status = gr.HTML("""
                        <div style="background: #f8f9fa; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                                    border-left: 4px solid #6c757d;">
                            <div style="color: #6c757d; font-size: 0.9rem;">
                                âš ï¸ è¯·å…ˆåˆ›å»ºæˆ–åŠ è½½ä¸€ä¸ªå°è¯´é¡¹ç›®
                            </div>
                        </div>
                        """)

                    # åŸºç¡€è®¾ç½®
                    topic_input = gr.Textbox(
                        label="ğŸ“ å°è¯´ä¸»é¢˜",
                        lines=3,
                        placeholder="æè¿°æ‚¨çš„å°è¯´ä¸»é¢˜ã€èƒŒæ™¯å’Œæ ¸å¿ƒæ•…äº‹...",
                        value=default_topic
                    )

                    with gr.Row():
                        genre_input = gr.Dropdown(
                            choices=genres,
                            label="ğŸ“š ç±»å‹",
                            value=default_genre,
                            allow_custom_value=True
                        )
                        num_chapters_input = gr.Number(
                            label="ğŸ“Š ç« èŠ‚æ•°",
                            value=default_num_chapters,
                            minimum=1,
                            maximum=1000
                        )
                        word_number_input = gr.Number(
                            label="ğŸ“„ æ¯ç« å­—æ•°",
                            value=default_word_number,
                            minimum=100,
                            maximum=10000
                        )

                    # é…ç½®ç®¡ç†
                    with gr.Row():
                        btn_load_config = gr.Button("ğŸ“¥ åŠ è½½é…ç½®", scale=1)
                        btn_save_config = gr.Button("ğŸ’¾ ä¿å­˜é…ç½®", scale=1)
                        btn_reset_params = gr.Button("ğŸ”„ é‡ç½®", variant="secondary", scale=1)

                    # é«˜çº§è®¾ç½® - æŠ˜å 
                    with gr.Accordion("ğŸ­ é«˜çº§è®¾ç½®", open=False):
                        characters_involved_input = gr.Textbox(
                            label="ğŸ‘¥ ä¸»è¦è§’è‰²",
                            lines=2,
                            value=default_characters_involved,
                            placeholder="ä¸»è§’ã€é…è§’ã€åæ´¾ç­‰è§’è‰²è®¾å®š..."
                        )

                        with gr.Row():
                            key_items_input = gr.Textbox(
                                label="ğŸ”‘ å…³é”®é“å…·",
                                value=default_key_items,
                                placeholder="é‡è¦ç‰©å“æˆ–é“å…·..."
                            )
                            scene_location_input = gr.Textbox(
                                label="ğŸŒ ä¸»è¦åœºæ™¯",
                                value=default_scene_location,
                                placeholder="æ•…äº‹å‘ç”Ÿåœ°ç‚¹..."
                            )
                            time_constraint_input = gr.Textbox(
                                label="â° æ—¶é—´è®¾å®š",
                                value=default_time_constraint,
                                placeholder="æ—¶ä»£èƒŒæ™¯æˆ–æ—¶é—´çº¦æŸ..."
                            )











                    # åˆ›ä½œè®¾ç½®
                    with gr.Row():
                        current_chapter = gr.Number(
                            label="ğŸ“– å½“å‰ç« èŠ‚",
                            value=1,
                            minimum=1,
                            step=1,
                            scale=1
                        )
                        user_guidance_input = gr.Textbox(
                            label="ğŸ“ åˆ›ä½œæŒ‡å¯¼",
                            lines=2,
                            value=default_user_guidance,
                            placeholder="æœ¬ç« çš„å…·ä½“åˆ›ä½œè¦æ±‚ï¼ˆå¯é€‰ï¼‰...",
                            scale=3
                        )
                    # AIç”Ÿæˆæ­¥éª¤
                    with gr.Row():
                        btn_step1 = gr.Button("ğŸ“‹ ç”Ÿæˆæ¶æ„", variant="primary", scale=1)
                        btn_step2 = gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False, scale=1)
                        btn_step3 = gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False, scale=1)
                        btn_step4 = gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False, scale=1)
                    # AIç”Ÿæˆç»“æœå±•ç¤ºåŒº - å·¦å³åˆ†æ å¸ƒå±€
                    with gr.Row():
                        # å·¦ä¾§ï¼šç”Ÿæˆæ§åˆ¶å’Œæ—¥å¿—åŒºåŸŸ (40%)
                        with gr.Column(scale=2):
                            # AIè¿è¡Œæ—¥å¿—
                            log_output = gr.Textbox(
                                label="ğŸ“‹ AIè¿è¡Œæ—¥å¿—",
                                lines=15,
                                max_lines=30,
                                interactive=False,
                                value="ğŸ¤– AIå°è¯´ç”Ÿæˆå™¨å·²å¯åŠ¨\nğŸ’¡ è¯·å…ˆé…ç½®AIæ¨¡å‹ï¼Œç„¶åæŒ‰æ­¥éª¤åˆ›ä½œ\n",
                                elem_classes=["log-container"],
                                autoscroll=True
                            )

                        # å³ä¾§ï¼šå†…å®¹é¢„è§ˆç¼–è¾‘åŒºåŸŸ
                        with gr.Column(scale=3):
                            # æ–‡ä»¶é¢„è§ˆTab
                            with gr.Tabs():
                                # å°è¯´æ¶æ„
                                with gr.Tab("ğŸ“‹ æ¶æ„"):
                                    architecture_content = gr.Textbox(
                                        label="",
                                        lines=15,
                                        max_lines=50,
                                        placeholder="ğŸ“‹ å°è¯´æ¶æ„å°†åœ¨è¿™é‡Œæ˜¾ç¤º...\n\nç‚¹å‡»å·¦ä¾§\"ç”Ÿæˆæ¶æ„\"æŒ‰é’®å¼€å§‹AIç”Ÿæˆã€‚",
                                        interactive=True,
                                        show_label=False,
                                        autoscroll=False,
                                        container=True,
                                        elem_classes=["scrollable-textbox"]
                                    )

                                # ç« èŠ‚è“å›¾
                                with gr.Tab("ğŸ“‘ ç›®å½•"):
                                    blueprint_content = gr.Textbox(
                                        label="",
                                        lines=15,
                                        max_lines=100,
                                        placeholder="ğŸ“‘ ç« èŠ‚ç›®å½•å°†åœ¨è¿™é‡Œæ˜¾ç¤º...\n\nå®Œæˆæ¶æ„åï¼Œç‚¹å‡»\"ç”Ÿæˆç›®å½•\"æŒ‰é’®ã€‚",
                                        interactive=True,
                                        show_label=False,
                                        autoscroll=False,
                                        container=True,
                                        elem_classes=["scrollable-textbox"]
                                    )

                                # å½“å‰ç« èŠ‚å†…å®¹
                                with gr.Tab("ğŸ“ ç« èŠ‚"):
                                    chapter_content = gr.Textbox(
                                        label="",
                                        lines=15,
                                        max_lines=200,
                                        placeholder="ğŸ“ ç« èŠ‚å†…å®¹å°†åœ¨è¿™é‡Œæ˜¾ç¤º...\n\nå®Œæˆå‰ä¸¤æ­¥åï¼Œç‚¹å‡»\"ç”Ÿæˆç« èŠ‚\"æŒ‰é’®ã€‚",
                                        interactive=True,
                                        show_label=False,
                                        autoscroll=False,
                                        container=True,
                                        elem_classes=["scrollable-textbox"]
                                    )

                                # æ‰€æœ‰ç« èŠ‚å†…å®¹
                                with gr.Tab("ğŸ“š æ‰€æœ‰ç« èŠ‚"):
                                    # ç« èŠ‚å¯¼èˆªæ§åˆ¶
                                    with gr.Row():
                                        with gr.Column(scale=1):
                                            chapter_selector = gr.Dropdown(
                                                label="é€‰æ‹©ç« èŠ‚",
                                                choices=[],
                                                value=None,
                                                interactive=True,
                                                allow_custom_value=False
                                            )
                                        with gr.Column(scale=2):
                                            with gr.Row():
                                                btn_prev_chapter = gr.Button("â¬…ï¸ ä¸Šä¸€ç« ", size="sm", scale=1)
                                                btn_next_chapter = gr.Button("ä¸‹ä¸€ç«  â¡ï¸", size="sm", scale=1)
                                                btn_refresh_chapters = gr.Button("ğŸ”„ åˆ·æ–°", size="sm", scale=1)

                                    # å•ä¸ªç« èŠ‚å†…å®¹æ˜¾ç¤º
                                    single_chapter_content = gr.Textbox(
                                        label="",
                                        lines=15,
                                        max_lines=300,
                                        placeholder="ğŸ“š é€‰æ‹©ç« èŠ‚æŸ¥çœ‹å†…å®¹...\n\nä»ä¸Šæ–¹ä¸‹æ‹‰èœå•é€‰æ‹©è¦æŸ¥çœ‹çš„ç« èŠ‚ã€‚",
                                        interactive=True,
                                        show_label=False,
                                        autoscroll=False,
                                        container=True,
                                        elem_classes=["scrollable-textbox"]
                                    )

                                    # æ‰€æœ‰ç« èŠ‚å†…å®¹ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
                                    with gr.Accordion("ğŸ“– æŸ¥çœ‹æ‰€æœ‰ç« èŠ‚", open=False):
                                        all_chapters_content = gr.Textbox(
                                            label="",
                                            lines=15,
                                            max_lines=300,
                                            placeholder="ğŸ“š æ‰€æœ‰ç« èŠ‚å†…å®¹å°†åœ¨è¿™é‡Œæ˜¾ç¤º...\n\nç”Ÿæˆç« èŠ‚åï¼Œè¿™é‡Œä¼šæ˜¾ç¤ºæ‰€æœ‰å·²å®Œæˆçš„ç« èŠ‚ã€‚",
                                            interactive=True,
                                            show_label=False,
                                            autoscroll=False,
                                            container=True,
                                            elem_classes=["scrollable-textbox"]
                                        )

                                # è§’è‰²çŠ¶æ€
                                with gr.Tab("ğŸ‘¥ è§’è‰²"):
                                    character_content = gr.Textbox(
                                        label="",
                                        lines=15,
                                        max_lines=80,
                                        placeholder="ğŸ‘¥ è§’è‰²çŠ¶æ€ä¿¡æ¯å°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
                                        interactive=True,
                                        show_label=False,
                                        autoscroll=False,
                                        container=True,
                                        elem_classes=["scrollable-textbox"]
                                    )

                                # å…¨å±€æ‘˜è¦
                                with gr.Tab("ğŸ“Š æ‘˜è¦"):
                                    summary_content = gr.Textbox(
                                        label="",
                                        lines=15,
                                        max_lines=60,
                                        placeholder="ğŸ“Š å…¨å±€æ‘˜è¦å°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
                                        interactive=True,
                                        show_label=False,
                                        autoscroll=False,
                                        container=True,
                                        elem_classes=["scrollable-textbox"]
                                    )

                        # with gr.Column(scale=1):
                        #     # AIç”Ÿæˆè¿›åº¦å’Œæ§åˆ¶
                        #     ai_generation_status = gr.HTML("""
                        #     <div style="background: #fff; border-radius: 12px; padding: 1rem; border: 2px solid #e0e0e0;">
                        #         <h4 style="margin: 0 0 1rem 0; color: #333; display: flex; align-items: center; gap: 0.5rem;">
                        #             âš¡ ç”Ÿæˆè¿›åº¦
                        #         </h4>
                        #         <div style="margin-bottom: 1rem;">
                        #             <div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
                        #                 <span style="font-size: 0.9rem; color: #666;">å½“å‰çŠ¶æ€:</span>
                        #                 <span style="font-size: 0.9rem; color: #666;">ç­‰å¾…å¼€å§‹</span>
                        #             </div>
                        #             <div style="background: #f5f5f5; border-radius: 10px; height: 8px; overflow: hidden;">
                        #                 <div style="background: #4caf50; height: 100%; width: 0%; transition: width 0.3s ease;"></div>
                        #             </div>
                        #         </div>

                        #         <div style="space-y: 0.5rem;">
                        #             <div style="display: flex; align-items: center; gap: 0.5rem; margin-bottom: 0.5rem;">
                        #                 <span style="width: 16px; height: 16px; background: #e0e0e0; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 0.7rem;">1</span>
                        #                 <span style="font-size: 0.85rem; color: #666;">æ¶æ„è®¾è®¡</span>
                        #             </div>
                        #             <div style="display: flex; align-items: center; gap: 0.5rem; margin-bottom: 0.5rem;">
                        #                 <span style="width: 16px; height: 16px; background: #e0e0e0; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 0.7rem;">2</span>
                        #                 <span style="font-size: 0.85rem; color: #666;">ç›®å½•è§„åˆ’</span>
                        #             </div>
                        #             <div style="display: flex; align-items: center; gap: 0.5rem; margin-bottom: 0.5rem;">
                        #                 <span style="width: 16px; height: 16px; background: #e0e0e0; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 0.7rem;">3</span>
                        #                 <span style="font-size: 0.85rem; color: #666;">ç« èŠ‚ç”Ÿæˆ</span>
                        #             </div>
                        #             <div style="display: flex; align-items: center; gap: 0.5rem; margin-bottom: 1rem;">
                        #                 <span style="width: 16px; height: 16px; background: #e0e0e0; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 0.7rem;">4</span>
                        #                 <span style="font-size: 0.85rem; color: #666;">å†…å®¹å®šç¨¿</span>
                        #             </div>
                        #         </div>

                        #         <div style="margin-top: 1rem;">
                        #             <button style="width: 100%; padding: 0.5rem; background: #f44336; color: white; border: none; border-radius: 8px; font-size: 0.85rem; cursor: pointer;" disabled>
                        #                 â¸ï¸ æš‚åœç”Ÿæˆ
                        #             </button>
                        #         </div>
                        #     </div>
                        #     """)



                    # å¿«é€Ÿæ“ä½œåŒºåŸŸ
                    with gr.Row():

                        # ç®€åŒ–çš„é…ç½®å’ŒçŠ¶æ€åŒºåŸŸ
                        with gr.Column():
                            # å¿«é€Ÿæ“ä½œé¢æ¿ï¼ˆæŠ˜å ï¼‰
                            with gr.Accordion("âš¡ å¿«é€Ÿæ“ä½œ", open=False):
                                gr.HTML("""
                                <div style="margin-bottom: 1rem; padding: 0.75rem; background: #f0f9ff; border-radius: 8px; border-left: 3px solid #0ea5e9;">
                                    <strong>ğŸš€ ä¸€é”®æ“ä½œ</strong><br>
                                    <small style="color: #0369a1;">
                                        å¿«é€Ÿæ‰§è¡Œå¸¸ç”¨çš„åˆ›ä½œå’Œç®¡ç†æ“ä½œ
                                    </small>
                                </div>
                                """)



                                with gr.Row():
                                    btn_consistency = gr.Button("ğŸ” ä¸€è‡´æ€§æ£€æŸ¥", elem_classes=["primary-button"], scale=1)
                                    btn_import_knowledge = gr.Button("ğŸ“š å¯¼å…¥çŸ¥è¯†åº“", elem_classes=["primary-button"], scale=1)

                                with gr.Row():
                                    btn_clear_vectorstore = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå‘é‡åº“", variant="stop", scale=1)
                                    btn_plot_arcs = gr.Button("ğŸ“Š æŸ¥çœ‹å‰§æƒ…è¦ç‚¹", elem_classes=["primary-button"], scale=1)

                # Tab 2: AIæ¨¡å‹é…ç½®
                with gr.Tab("ğŸ¤– AIæ¨¡å‹é…ç½®", id="config"):
                    # AIæ¨¡å‹é…ç½®å¼•å¯¼
                    # with gr.Row():
                    #     ai_config_header = gr.HTML("""
                    #     <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    #                 color: white; padding: 2rem; border-radius: 15px; margin-bottom: 1.5rem;
                    #                 box-shadow: 0 4px 20px rgba(102,126,234,0.3);">
                    #         <div style="text-align: center;">
                    #             <h2 style="margin: 0 0 1rem 0; font-size: 1.6rem; display: flex; align-items: center; justify-content: center; gap: 0.5rem;">
                    #                 ğŸ§  AIå¤§è„‘é…ç½®ä¸­å¿ƒ
                    #             </h2>
                    #             <p style="margin: 0 0 1rem 0; opacity: 0.9; font-size: 1rem; max-width: 600px; margin-left: auto; margin-right: auto;">
                    #                 é…ç½®AIæ¨¡å‹æ˜¯å¼€å§‹åˆ›ä½œçš„ç¬¬ä¸€æ­¥ã€‚é€‰æ‹©åˆé€‚çš„AIå¤§è„‘ï¼Œè®©å®ƒä¸ºæ‚¨åˆ›ä½œå‡ºç²¾å½©çš„å°è¯´å†…å®¹ã€‚
                    #             </p>
                    #             <div style="display: flex; justify-content: center; gap: 2rem; margin-top: 1.5rem; flex-wrap: wrap;">
                    #                 <div style="text-align: center;">
                    #                     <div style="font-size: 2rem; margin-bottom: 0.5rem;">ğŸ¤–</div>
                    #                     <div style="font-size: 0.9rem; opacity: 0.9;">æ™ºèƒ½åˆ›ä½œ</div>
                    #                 </div>
                    #                 <div style="text-align: center;">
                    #                     <div style="font-size: 2rem; margin-bottom: 0.5rem;">âš¡</div>
                    #                     <div style="font-size: 0.9rem; opacity: 0.9;">å¿«é€Ÿé…ç½®</div>
                    #                 </div>
                    #                 <div style="text-align: center;">
                    #                     <div style="font-size: 2rem; margin-bottom: 0.5rem;">ğŸ¯</div>
                    #                     <div style="font-size: 0.9rem; opacity: 0.9;">ç²¾å‡†ç”Ÿæˆ</div>
                    #                 </div>
                    #             </div>
                    #         </div>
                    #     </div>
                    #     """)
                    # AIæ¨¡å‹çŠ¶æ€æ¦‚è§ˆ
                    with gr.Row():
                        config_status_display = gr.HTML("""
                        <div style="background: #f8f9fa; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem;
                                    border-left: 4px solid #ffc107;">
                            <div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap;">
                                <div>
                                    <h3 style="margin: 0 0 1rem 0; color: #333; font-size: 1.1rem;">ğŸ” AIæ¨¡å‹çŠ¶æ€æ£€æŸ¥</h3>
                                    <div style="display: flex; gap: 2rem; flex-wrap: wrap;">
                                        <div style="display: flex; align-items: center; gap: 0.5rem;">
                                            <span style="width: 12px; height: 12px; background: #ffc107; border-radius: 50%;"></span>
                                            <span style="font-weight: 500; color: #856404;">åˆ›ä½œå¤§è„‘: å¾…é…ç½®</span>
                                        </div>
                                        <div style="display: flex; align-items: center; gap: 0.5rem;">
                                            <span style="width: 12px; height: 12px; background: #ffc107; border-radius: 50%;"></span>
                                            <span style="font-weight: 500; color: #856404;">ç†è§£å¼•æ“: å¾…é…ç½®</span>
                                        </div>
                                    </div>
                                </div>
                                <div style="text-align: center; padding: 1rem; background: #fff3cd; border-radius: 8px;">
                                    <div style="font-size: 1.5rem; font-weight: bold; color: #856404;">âš ï¸</div>
                                    <div style="font-size: 0.85rem; color: #856404; margin-top: 0.25rem;">éœ€è¦é…ç½®</div>
                                </div>
                            </div>
                        </div>
                        """)

                    # ä¸€é”®é…ç½®
                    gr.HTML("""
                    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                color: white; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;
                                text-align: center;">
                        <h3 style="margin: 0;">âš¡ ä¸€é”®AIé…ç½®</h3>
                    </div>
                    """)

                    with gr.Row():
                        template_openai = gr.Button(
                            "ğŸš€ OpenAI GPT",
                            variant="primary",
                            scale=1
                        )
                        template_gemini = gr.Button(
                            "ğŸ’ Google Gemini",
                            variant="secondary",
                            scale=1
                        )
                        template_deepseek = gr.Button(
                            "ğŸ”¥ DeepSeek",
                            variant="secondary",
                            scale=1
                        )

                    # é…ç½®å®Œæˆåçš„å¼•å¯¼
                    with gr.Row():
                        config_success_guide = gr.HTML("""
                        <div style="background: #d4edda; border-radius: 12px; padding: 1.5rem; margin-top: 1rem;
                                    border-left: 4px solid #28a745; display: none;" id="config-success-guide">
                            <div style="text-align: center;">
                                <h4 style="margin: 0 0 1rem 0; color: #155724; display: flex; align-items: center; justify-content: center; gap: 0.5rem;">
                                    âœ… AIå¤§è„‘é…ç½®å®Œæˆï¼
                                </h4>
                                <p style="margin: 0 0 1rem 0; color: #155724;">
                                    æ‚¨çš„AIåˆ›ä½œåŠ©æ‰‹å·²å‡†å¤‡å°±ç»ªï¼Œç°åœ¨å¯ä»¥å¼€å§‹åˆ›ä½œæ‚¨çš„å°è¯´äº†ï¼
                                </p>
                                <button onclick="switchToMainTab()" style="background: #28a745; color: white; border: none;
                                        padding: 0.75rem 2rem; border-radius: 8px; font-size: 1rem; cursor: pointer;
                                        box-shadow: 0 2px 4px rgba(40,167,69,0.3);">
                                    ğŸš€ ç«‹å³å¼€å§‹AIåˆ›ä½œ
                                </button>
                            </div>
                        </div>
                        """, visible=False)

                    # è¯¦ç»†é…ç½®
                    with gr.Accordion("ğŸ”§ è¯¦ç»†é…ç½®", open=False):

                        # AIåˆ›ä½œé…ç½®
                        gr.HTML("<h4>ğŸ§  AIåˆ›ä½œé…ç½®</h4>")

                        with gr.Row():
                            llm_interface = gr.Dropdown(
                                choices=llm_interfaces,
                                label="ğŸ¤– æœåŠ¡å•†",
                                value=default_llm_interface,
                                scale=1
                            )
                            llm_model = gr.Textbox(
                                label="ğŸ§  æ¨¡å‹",
                                value=default_llm_model,
                                placeholder="ä¾‹å¦‚: gpt-4o-mini",
                                scale=1
                            )

                        llm_api_key = gr.Textbox(
                            label="ğŸ”‘ APIå¯†é’¥",
                            type="password",
                            value=default_llm_api_key,
                            placeholder="sk-... æˆ–å…¶ä»–æ ¼å¼çš„APIå¯†é’¥"
                        )

                        # é«˜çº§å‚æ•°
                        with gr.Accordion("ğŸ›ï¸ é«˜çº§å‚æ•°", open=False):
                            llm_base_url = gr.Textbox(
                                label="ğŸŒ æœåŠ¡åœ°å€",
                                value=default_llm_base_url,
                                placeholder="https://api.openai.com/v1"
                            )

                            with gr.Row():
                                temperature = gr.Slider(
                                    label="ğŸ¨ åˆ›æ„åº¦",
                                    minimum=0.0,
                                    maximum=2.0,
                                    value=default_temperature,
                                    step=0.1
                                )
                                max_tokens = gr.Number(
                                    label="ğŸ“ è¾“å‡ºé•¿åº¦",
                                    value=default_max_tokens,
                                    minimum=100,
                                    maximum=32000
                                )
                                timeout = gr.Number(
                                    label="â±ï¸ å“åº”æ—¶é—´",
                                    value=default_timeout,
                                    minimum=10,
                                    maximum=3600
                                )

                        # æµ‹è¯•å’Œä¿å­˜
                        with gr.Row():
                            btn_test_llm = gr.Button(
                                "ğŸ§ª æµ‹è¯•AI",
                                variant="primary",
                                scale=2
                            )
                            btn_save_llm = gr.Button(
                                "ğŸ’¾ ä¿å­˜é…ç½®",
                                variant="secondary",
                                scale=1
                            )

                        # çŠ¶æ€æ˜¾ç¤º
                        llm_status = gr.HTML("""
                        <div style="margin: 1rem 0; padding: 0.75rem; background: #fff3cd;
                                    border-radius: 8px; border-left: 3px solid #ffc107;">
                            <div style="font-weight: 500; color: #856404;">âš ï¸ æœªæµ‹è¯•</div>
                            <div style="font-size: 0.85rem; color: #856404;">è¯·å…ˆæµ‹è¯•é…ç½®ç¡®ä¿è¿æ¥æ­£å¸¸</div>
                        </div>
                        """)
                        # AIç†è§£é…ç½®
                        gr.HTML("<h4>ğŸ” AIç†è§£é…ç½®</h4>")

                        with gr.Row():
                            embedding_interface = gr.Dropdown(
                                choices=llm_interfaces,
                                label="ğŸ¤– æœåŠ¡å•†",
                                value=default_embedding_interface,
                                scale=1
                            )
                            embedding_model = gr.Textbox(
                                label="ğŸ§  æ¨¡å‹",
                                value=default_embedding_model,
                                placeholder="ä¾‹å¦‚: text-embedding-ada-002",
                                scale=1
                            )

                        use_same_key = gr.Checkbox(
                            label="ğŸ”— ä¸åˆ›ä½œAIä½¿ç”¨ç›¸åŒé…ç½®",
                            value=True
                        )

                        # APIå¯†é’¥è®¾ç½®
                        with gr.Group(visible=False) as embedding_api_group:
                            embedding_api_key = gr.Textbox(
                                label="ğŸ”‘ APIå¯†é’¥",
                                type="password",
                                value=default_embedding_api_key,
                                placeholder="è¯·è¾“å…¥ä¸“ç”¨APIå¯†é’¥"
                            )
                            embedding_base_url = gr.Textbox(
                                label="ğŸŒ æœåŠ¡åœ°å€",
                                value=default_embedding_base_url,
                                placeholder="https://api.openai.com/v1"
                            )

                            # æµ‹è¯•æŒ‰é’®
                            with gr.Row():
                                btn_test_embedding = gr.Button(
                                    "ğŸ§ª æµ‹è¯•ç†è§£AI",
                                    variant="primary",
                                    scale=2
                                )
                                btn_save_embedding = gr.Button(
                                    "ğŸ’¾ ä¿å­˜é…ç½®",
                                    variant="secondary",
                                    scale=1
                                )

                        # é«˜çº§å‚æ•°
                        with gr.Accordion("ğŸ›ï¸ ç†è§£å‚æ•°", open=False):
                            retrieval_k = gr.Number(
                                label="ğŸ” æ£€ç´¢æ•°é‡",
                                value=default_retrieval_k,
                                minimum=1,
                                maximum=20
                            )

                        # çŠ¶æ€æ˜¾ç¤º
                        embedding_status = gr.HTML("""
                        <div style="margin: 1rem 0; padding: 0.75rem; background: #fff3cd;
                                    border-radius: 8px; border-left: 3px solid #ffc107;">
                            <div style="font-weight: 500; color: #856404;">âš ï¸ æœªæµ‹è¯•</div>
                            <div style="font-size: 0.85rem; color: #856404;">è¯·å…ˆæµ‹è¯•é…ç½®ç¡®ä¿è¿æ¥æ­£å¸¸</div>
                        </div>
                        """)

                    with gr.Column(scale=2):
                        # é…ç½®æµ‹è¯•æ—¥å¿—åŒºåŸŸ
                        with gr.Group():
                            gr.HTML("""
                            <div style="background: linear-gradient(135deg, #6c757d 0%, #495057 100%);
                                        color: white; padding: 1rem; border-radius: 10px 10px 0 0; margin: -1rem -1rem 1rem -1rem;">
                                <h3 style="margin: 0; display: flex; align-items: center; gap: 0.5rem;">
                                    ğŸ“‹ é…ç½®æµ‹è¯•æ—¥å¿—
                                    <span style="background: rgba(255,255,255,0.2); padding: 0.2rem 0.5rem;
                                                 border-radius: 12px; font-size: 0.8rem;">å®æ—¶ç›‘æ§</span>
                                </h3>
                                <p style="margin: 0.5rem 0 0 0; opacity: 0.9; font-size: 0.9rem;">
                                    å®æ—¶æ˜¾ç¤ºæ¨¡å‹é…ç½®æµ‹è¯•çš„è¯¦ç»†è¿‡ç¨‹å’Œç»“æœ
                                </p>
                            </div>
                            """)

                            config_log_output = gr.Textbox(
                                label="æµ‹è¯•æ—¥å¿—",
                                lines=15,
                                max_lines=20,
                                interactive=False,
                                value="",
                                placeholder="ğŸ’¡ ç‚¹å‡»æµ‹è¯•æŒ‰é’®æŸ¥çœ‹è¯¦ç»†æ—¥å¿—...\n\nğŸ” è¿™é‡Œä¼šæ˜¾ç¤ºï¼š\nâ€¢ è¿æ¥çŠ¶æ€å’Œå“åº”æ—¶é—´\nâ€¢ è¯·æ±‚å‚æ•°å’Œé…ç½®éªŒè¯\nâ€¢ æ¨¡å‹å“åº”ç»“æœ\nâ€¢ é”™è¯¯è¯Šæ–­å’Œè§£å†³å»ºè®®\nâ€¢ æ€§èƒ½æŒ‡æ ‡å’Œä¼˜åŒ–å»ºè®®",
                                elem_classes=["log-container"]
                            )

                            with gr.Row():
                                btn_clear_config_log = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—", variant="secondary", scale=1)
                                btn_export_log = gr.Button("ğŸ“¤ å¯¼å‡ºæ—¥å¿—", variant="secondary", scale=1)

                            # AIé…ç½®æ™ºèƒ½æ¨è
                            with gr.Group():
                                gr.HTML("""
                                <div style="background: linear-gradient(135deg, #17a2b8 0%, #138496 100%);
                                            color: white; padding: 1rem; border-radius: 10px 10px 0 0; margin: -1rem -1rem 1rem -1rem;">
                                    <h3 style="margin: 0;">ğŸ¯ AIé…ç½®æ™ºèƒ½æ¨è</h3>
                                    <p style="margin: 0.5rem 0 0 0; opacity: 0.9; font-size: 0.9rem;">
                                        æ ¹æ®ä¸åŒåˆ›ä½œéœ€æ±‚ï¼Œä¸ºæ‚¨æ¨èæœ€é€‚åˆçš„AIå¤§è„‘é…ç½®
                                    </p>
                                </div>
                                """)

                                config_suggestions = gr.HTML("""
                                <div style="padding: 1rem 0;">
                                    <div style="margin-bottom: 1rem; padding: 0.75rem; background: #e7f3ff; border-radius: 8px; border-left: 3px solid #007bff;">
                                        <h4 style="margin: 0 0 0.5rem 0; color: #0056b3;">ğŸš€ æ–°æ‰‹ä½œå®¶</h4>
                                        <ul style="margin: 0; padding-left: 1.2rem; color: #0056b3;">
                                            <li>AIå¤§è„‘: OpenAI GPT-4o-mini (å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬)</li>
                                            <li>åˆ›æ„åº¦: 0.7 (å¹³è¡¡åˆ›ä½œ)</li>
                                            <li>è¾“å‡ºé•¿åº¦: 4096å­— (é€‚ä¸­ç¯‡å¹…)</li>
                                        </ul>
                                    </div>

                                    <div style="margin-bottom: 1rem; padding: 0.75rem; background: #f0f9ff; border-radius: 8px; border-left: 3px solid #0ea5e9;">
                                        <h4 style="margin: 0 0 0.5rem 0; color: #0369a1;">ğŸ’ å…è´¹ä½“éªŒ</h4>
                                        <ul style="margin: 0; padding-left: 1.2rem; color: #0369a1;">
                                            <li>AIå¤§è„‘: Google Gemini Flash (å…è´¹é¢åº¦å……è¶³)</li>
                                            <li>åˆ›æ„åº¦: 0.8 (ç¨é«˜åˆ›æ„)</li>
                                            <li>è¾“å‡ºé•¿åº¦: 8192å­— (é•¿ç¯‡åˆ›ä½œ)</li>
                                        </ul>
                                    </div>

                                    <div style="margin-bottom: 1rem; padding: 0.75rem; background: #fef3e2; border-radius: 8px; border-left: 3px solid #f59e0b;">
                                        <h4 style="margin: 0 0 0.5rem 0; color: #92400e;">ğŸ”¥ ç»æµå®æƒ </h4>
                                        <ul style="margin: 0; padding-left: 1.2rem; color: #92400e;">
                                            <li>AIå¤§è„‘: DeepSeek Chat (å›½äº§ä¼˜è´¨ï¼Œä»·æ ¼äº²æ°‘)</li>
                                            <li>åˆ›æ„åº¦: 0.9 (é«˜åº¦åˆ›æ–°)</li>
                                            <li>è¾“å‡ºé•¿åº¦: 6144å­— (ä¸­é•¿ç¯‡)</li>
                                        </ul>
                                    </div>

                                    <div style="padding: 0.75rem; background: #f0fdf4; border-radius: 8px; border-left: 3px solid #22c55e;">
                                        <h4 style="margin: 0 0 0.5rem 0; color: #166534;">âš¡ ä¸“ä¸šä½œå®¶</h4>
                                        <ul style="margin: 0; padding-left: 1.2rem; color: #166534;">
                                            <li>AIå¤§è„‘: OpenAI GPT-4 (é¡¶çº§åˆ›ä½œè´¨é‡)</li>
                                            <li>åˆ›æ„åº¦: 0.6 (ç²¾å‡†æ§åˆ¶)</li>
                                            <li>è¾“å‡ºé•¿åº¦: 8192å­— (ä¸“ä¸šé•¿åº¦)</li>
                                        </ul>
                                    </div>
                                </div>
                                """)

                        # é…ç½®çŠ¶æ€å¡ç‰‡
                        gr.HTML("""
                        <div class="feature-card">
                            <h4>ğŸ“Š é…ç½®çŠ¶æ€</h4>
                            <div style="margin: 0.5rem 0;">
                                <div style="margin: 0.3rem 0;">
                                    <span class="status-indicator status-warning"></span>
                                    <span style="font-size: 0.9rem;">LLM: å¾…æµ‹è¯•</span>
                                </div>
                                <div style="margin: 0.3rem 0;">
                                    <span class="status-indicator status-warning"></span>
                                    <span style="font-size: 0.9rem;">Embedding: å¾…æµ‹è¯•</span>
                                </div>
                            </div>
                        </div>
                        """)

                        # æ¨èé…ç½®
                        gr.HTML("""
                        <div class="feature-card">
                            <h4>ğŸ’¡ æ¨èé…ç½®</h4>
                            <div style="font-size: 0.85rem; line-height: 1.5;">
                                <strong>ğŸš€ å¿«é€Ÿå¼€å§‹:</strong><br>
                                â€¢ OpenAI: gpt-4o-mini<br>
                                â€¢ Gemini: gemini-1.5-flash<br>
                                â€¢ DeepSeek: deepseek-chat<br><br>
                                <strong>âš™ï¸ å‚æ•°å»ºè®®:</strong><br>
                                â€¢ Temperature: 0.7-0.9<br>
                                â€¢ Max Tokens: 4096-8192<br>
                                â€¢ Timeout: 60-300ç§’
                            </div>
                        </div>
                        """)





        # åœ¨Blocksä¸Šä¸‹æ–‡å†…ç›´æ¥è®¾ç½®äº‹ä»¶å¤„ç†å™¨
        # é…ç½®ç›¸å…³äº‹ä»¶
        btn_load_config.click(
            fn=handle_load_config,
            outputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout,
                embedding_interface, embedding_api_key, embedding_base_url,
                embedding_model, retrieval_k,
                topic_input, genre_input, num_chapters_input,
                word_number_input, project_path_input, user_guidance_input,
                characters_involved_input, key_items_input,
                scene_location_input, time_constraint_input,
                log_output
            ]
        )



        btn_save_config.click(
            fn=handle_save_config,
            inputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout,
                embedding_interface, embedding_api_key, embedding_base_url,
                embedding_model, retrieval_k,
                topic_input, genre_input, num_chapters_input,
                word_number_input, project_path_input, user_guidance_input,
                characters_involved_input, key_items_input,
                scene_location_input, time_constraint_input
            ],
            outputs=log_output
        )

        # é¡¹ç›®ç®¡ç†äº‹ä»¶
        btn_browse_folder.click(
            fn=handle_browse_folder,
            outputs=project_path_input
        )

        btn_create_project.click(
            fn=handle_create_project_and_load,
            inputs=project_path_input,
            outputs=[
                project_path_input, project_status, log_output,
                architecture_content, blueprint_content, chapter_content,
                all_chapters_content, character_content, summary_content,
                btn_step2, btn_step3, btn_step4, chapter_selector, single_chapter_content,
                topic_input, genre_input, num_chapters_input, word_number_input,
                user_guidance_input, characters_involved_input, key_items_input,
                scene_location_input, time_constraint_input
            ]
        )

        btn_load_project.click(
            fn=handle_load_project_and_load,
            inputs=project_path_input,
            outputs=[
                project_path_input, project_status, log_output,
                architecture_content, blueprint_content, chapter_content,
                all_chapters_content, character_content, summary_content,
                btn_step2, btn_step3, btn_step4, chapter_selector, single_chapter_content,
                topic_input, genre_input, num_chapters_input, word_number_input,
                user_guidance_input, characters_involved_input, key_items_input,
                scene_location_input, time_constraint_input
            ]
        )

        # æµ‹è¯•é…ç½®äº‹ä»¶
        btn_test_llm.click(
            fn=handle_test_llm_config,
            inputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout, config_log_output
            ],
            outputs=[config_log_output, llm_status, config_status_display]
        )

        btn_test_embedding.click(
            fn=handle_test_embedding_config,
            inputs=[
                embedding_interface, embedding_api_key,
                embedding_base_url, embedding_model, config_log_output,
                use_same_key, llm_api_key, llm_base_url
            ],
            outputs=[config_log_output, embedding_status, config_status_display]
        )

        # æ¸…ç©ºé…ç½®æ—¥å¿—äº‹ä»¶
        btn_clear_config_log.click(
            fn=handle_clear_config_log,
            outputs=[config_log_output, llm_status, embedding_status, config_status_display]
        )

        # Embedding APIå¯†é’¥åŒæ­¥é€‰é¡¹äº‹ä»¶
        def toggle_embedding_api_group(use_same):
            """åˆ‡æ¢Embedding APIè®¾ç½®ç»„çš„æ˜¾ç¤ºçŠ¶æ€"""
            return gr.Group(visible=not use_same)

        use_same_key.change(
            fn=toggle_embedding_api_group,
            inputs=[use_same_key],
            outputs=[embedding_api_group]
        )

        # å¿«é€Ÿé…ç½®å’Œå¼€å§‹æŒ‰é’®äº‹ä»¶
        quick_config_btn.click(
            fn=lambda: None,
            js="() => { document.querySelector('[data-testid=\"tab-config\"]').click(); }"
        )

        quick_start_btn.click(
            fn=lambda: None,
            js="() => { document.querySelector('[data-testid=\"tab-main\"]').click(); }"
        )







        # æ ¸å¿ƒç”ŸæˆåŠŸèƒ½äº‹ä»¶
        btn_step1.click(
            fn=handle_generate_architecture,
            inputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout,
                topic_input, genre_input, num_chapters_input,
                word_number_input, project_path_input, user_guidance_input,
                log_output
            ],
            outputs=[log_output, architecture_content, btn_step2]
        )

        btn_step2.click(
            fn=handle_generate_blueprint,
            inputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout,
                project_path_input, num_chapters_input, user_guidance_input, log_output
            ],
            outputs=[log_output, blueprint_content, btn_step3]
        )

        btn_step3.click(
            fn=handle_generate_chapter_draft,
            inputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout,
                embedding_interface, embedding_api_key, embedding_base_url,
                embedding_model, retrieval_k,
                project_path_input, current_chapter, word_number_input, user_guidance_input,
                log_output
            ],
            outputs=[chapter_content, all_chapters_content, log_output, btn_step4, current_chapter, chapter_selector]
        )

        btn_step4.click(
            fn=handle_finalize_chapter,
            inputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout,
                embedding_interface, embedding_api_key, embedding_base_url,
                embedding_model,
                project_path_input, current_chapter, word_number_input, chapter_content,
                log_output
            ],
            outputs=[log_output, character_content, summary_content, current_chapter, chapter_selector]
        )

        # è¾…åŠ©åŠŸèƒ½äº‹ä»¶
        btn_consistency.click(
            fn=handle_consistency_check,
            inputs=[
                llm_interface, llm_api_key, llm_base_url,
                llm_model, temperature, max_tokens, timeout,
                project_path_input, current_chapter, log_output
            ],
            outputs=log_output
        )

        btn_import_knowledge.click(
            fn=handle_import_knowledge,
            inputs=[project_path_input, log_output],
            outputs=log_output
        )

        btn_clear_vectorstore.click(
            fn=handle_clear_vectorstore,
            inputs=[project_path_input, log_output],
            outputs=log_output
        )

        # ç« èŠ‚åˆ‡æ¢äº‹ä»¶
        chapter_selector.change(
            fn=handle_chapter_selection,
            inputs=[project_path_input, chapter_selector],
            outputs=single_chapter_content
        )

        btn_prev_chapter.click(
            fn=handle_prev_chapter,
            inputs=[project_path_input, chapter_selector],
            outputs=[chapter_selector, single_chapter_content]
        )

        btn_next_chapter.click(
            fn=handle_next_chapter,
            inputs=[project_path_input, chapter_selector],
            outputs=[chapter_selector, single_chapter_content]
        )

        btn_refresh_chapters.click(
            fn=handle_refresh_chapters,
            inputs=[project_path_input, chapter_selector],
            outputs=[chapter_selector, single_chapter_content]
        )

        # é¡¹ç›®è·¯å¾„å˜åŒ–æ—¶è‡ªåŠ¨æ£€æŸ¥æ–‡ä»¶çŠ¶æ€å¹¶åŠ è½½å°è¯´é…ç½®
        project_path_input.change(
            fn=handle_filepath_change,
            inputs=project_path_input,
            outputs=[
                log_output, architecture_content, blueprint_content,
                chapter_content, all_chapters_content, character_content, summary_content,
                btn_step2, btn_step3, btn_step4, chapter_selector, single_chapter_content,
                topic_input, genre_input, num_chapters_input, word_number_input,
                user_guidance_input, characters_involved_input, key_items_input,
                scene_location_input, time_constraint_input
            ]
        )

        btn_plot_arcs.click(
            fn=handle_show_plot_arcs,
            inputs=[project_path_input, log_output],
            outputs=log_output
        )

        # ç®€åŒ–åçš„æ–‡ä»¶ç®¡ç† - é€šè¿‡AIç”Ÿæˆæ­¥éª¤è‡ªåŠ¨æ›´æ–°å†…å®¹

        # é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨æ£€æŸ¥æ–‡ä»¶çŠ¶æ€ï¼ˆå¦‚æœæœ‰é»˜è®¤è·¯å¾„ï¼‰
        if default_filepath:
            demo.load(
                fn=lambda: handle_filepath_change(default_filepath),
                outputs=[
                    log_output, architecture_content, blueprint_content,
                    chapter_content, all_chapters_content, character_content, summary_content,
                    btn_step2, btn_step3, btn_step4
                ]
            )

        return demo

# äº‹ä»¶å¤„ç†å‡½æ•°
def handle_load_config():
    """å¤„ç†åŠ è½½é…ç½®äº‹ä»¶"""
    config_data, message = app.load_config_from_file()
    if config_data:
        return (
            config_data["llm_interface"],
            config_data["llm_api_key"],
            config_data["llm_base_url"],
            config_data["llm_model"],
            config_data["temperature"],
            config_data["max_tokens"],
            config_data["timeout"],
            config_data["embedding_interface"],
            config_data["embedding_api_key"],
            config_data["embedding_base_url"],
            config_data["embedding_model"],
            config_data["retrieval_k"],
            config_data["topic"],
            config_data["genre"],
            config_data["num_chapters"],
            config_data["word_number"],
            config_data["filepath"],
            config_data["user_guidance"],
            config_data["characters_involved"],
            config_data["key_items"],
            config_data["scene_location"],
            config_data["time_constraint"],
            message
        )
    else:
        return (
            "OpenAI", "", "https://api.openai.com/v1", "gpt-4o-mini", 0.7, 8192, 600,
            "OpenAI", "", "https://api.openai.com/v1", "text-embedding-ada-002", 4,
            "", "ç„å¹»", 10, 3000, "", "", "", "", "", "",
            message
        )


def handle_load_novel_config(filepath):
    """å¤„ç†åŠ è½½å°è¯´é…ç½®äº‹ä»¶"""
    if not filepath or not filepath.strip():
        return (
            "", "ç„å¹»", 10, 3000, "", "", "", "", "",
            app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„")
        )

    config_data, message = app.load_config_from_file(filepath.strip())
    if config_data:
        return (
            config_data["topic"],
            config_data["genre"],
            config_data["num_chapters"],
            config_data["word_number"],
            config_data["user_guidance"],
            config_data["characters_involved"],
            config_data["key_items"],
            config_data["scene_location"],
            config_data["time_constraint"],
            app.log_message(f"âœ… å·²åŠ è½½å°è¯´é…ç½®: {message}")
        )
    else:
        return (
            "", "ç„å¹»", 10, 3000, "", "", "", "", "",
            app.log_message(f"âŒ åŠ è½½å°è¯´é…ç½®å¤±è´¥: {message}")
        )


def handle_create_project(project_path):
    """å¤„ç†åˆ›å»ºæ–°é¡¹ç›®äº‹ä»¶"""
    if not project_path or not project_path.strip():
        return (
            project_path,
            """<div style="background: #f8d7da; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                        border-left: 4px solid #dc3545;">
                <div style="color: #721c24; font-size: 0.9rem;">
                    âŒ è¯·è¾“å…¥é¡¹ç›®è·¯å¾„
                </div>
            </div>""",
            app.log_message("âŒ è¯·è¾“å…¥é¡¹ç›®è·¯å¾„")
        )

    try:
        project_path = project_path.strip()
        # åˆ›å»ºé¡¹ç›®ç›®å½•
        os.makedirs(project_path, exist_ok=True)

        # åˆ›å»ºåŸºæœ¬çš„é¡¹ç›®ç»“æ„
        chapters_dir = os.path.join(project_path, "chapters")
        os.makedirs(chapters_dir, exist_ok=True)

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰é…ç½®æ–‡ä»¶
        config_file = os.path.join(project_path, "novel_config.json")
        project_name = os.path.basename(project_path)

        if os.path.exists(config_file):
            status_html = f"""<div style="background: #fff3cd; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                                border-left: 4px solid #ffc107;">
                <div style="color: #856404; font-size: 0.9rem;">
                    âš ï¸ é¡¹ç›® "{project_name}" å·²å­˜åœ¨ï¼Œå·²åŠ è½½ç°æœ‰é…ç½®
                </div>
            </div>"""
            log_msg = f"âœ… é¡¹ç›® '{project_name}' å·²å­˜åœ¨ï¼Œå·²åŠ è½½ç°æœ‰é…ç½®"
        else:
            # åˆ›å»ºé»˜è®¤é…ç½®
            default_config = {
                "topic": "",
                "genre": "ç„å¹»",
                "num_chapters": 10,
                "word_number": 3000,
                "filepath": project_path,
                "user_guidance": "",
                "characters_involved": "",
                "key_items": "",
                "scene_location": "",
                "time_constraint": ""
            }
            save_config(default_config, config_file)

            status_html = f"""<div style="background: #d4edda; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                                border-left: 4px solid #28a745;">
                <div style="color: #155724; font-size: 0.9rem;">
                    âœ… é¡¹ç›® "{project_name}" åˆ›å»ºæˆåŠŸï¼å¯ä»¥å¼€å§‹åˆ›ä½œäº†
                </div>
            </div>"""
            log_msg = f"âœ… æ–°é¡¹ç›® '{project_name}' åˆ›å»ºæˆåŠŸ"

        return (
            project_path,
            status_html,
            app.log_message(log_msg)
        )

    except Exception as e:
        error_html = f"""<div style="background: #f8d7da; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                            border-left: 4px solid #dc3545;">
            <div style="color: #721c24; font-size: 0.9rem;">
                âŒ åˆ›å»ºé¡¹ç›®å¤±è´¥: {str(e)}
            </div>
        </div>"""
        return (
            project_path,
            error_html,
            app.log_message(f"âŒ åˆ›å»ºé¡¹ç›®å¤±è´¥: {str(e)}")
        )


def handle_load_project(project_path):
    """å¤„ç†åŠ è½½é¡¹ç›®äº‹ä»¶"""
    if not project_path or not project_path.strip():
        return (
            project_path,
            """<div style="background: #f8d7da; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                        border-left: 4px solid #dc3545;">
                <div style="color: #721c24; font-size: 0.9rem;">
                    âŒ è¯·è¾“å…¥é¡¹ç›®è·¯å¾„
                </div>
            </div>""",
            app.log_message("âŒ è¯·è¾“å…¥é¡¹ç›®è·¯å¾„")
        )

    try:
        project_path = project_path.strip()
        project_name = os.path.basename(project_path)

        # æ£€æŸ¥é¡¹ç›®ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(project_path):
            error_html = f"""<div style="background: #f8d7da; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                                border-left: 4px solid #dc3545;">
                <div style="color: #721c24; font-size: 0.9rem;">
                    âŒ é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_path}
                </div>
            </div>"""
            return (
                project_path,
                error_html,
                app.log_message(f"âŒ é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_path}")
            )

        # æ£€æŸ¥æ˜¯å¦æœ‰é…ç½®æ–‡ä»¶
        config_file = os.path.join(project_path, "novel_config.json")
        if os.path.exists(config_file):
            status_html = f"""<div style="background: #d4edda; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                                border-left: 4px solid #28a745;">
                <div style="color: #155724; font-size: 0.9rem;">
                    âœ… é¡¹ç›® "{project_name}" åŠ è½½æˆåŠŸï¼
                </div>
            </div>"""
            log_msg = f"âœ… é¡¹ç›® '{project_name}' åŠ è½½æˆåŠŸ"
        else:
            status_html = f"""<div style="background: #fff3cd; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                                border-left: 4px solid #ffc107;">
                <div style="color: #856404; font-size: 0.9rem;">
                    âš ï¸ é¡¹ç›® "{project_name}" åŠ è½½æˆåŠŸï¼Œä½†æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤è®¾ç½®
                </div>
            </div>"""
            log_msg = f"âš ï¸ é¡¹ç›® '{project_name}' åŠ è½½æˆåŠŸï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®"

        return (
            project_path,
            status_html,
            app.log_message(log_msg)
        )

    except Exception as e:
        error_html = f"""<div style="background: #f8d7da; border-radius: 8px; padding: 1rem; margin-top: 1rem;
                            border-left: 4px solid #dc3545;">
            <div style="color: #721c24; font-size: 0.9rem;">
                âŒ åŠ è½½é¡¹ç›®å¤±è´¥: {str(e)}
            </div>
        </div>"""
        return (
            project_path,
            error_html,
            app.log_message(f"âŒ åŠ è½½é¡¹ç›®å¤±è´¥: {str(e)}")
        )


def handle_create_project_and_load(project_path):
    """å¤„ç†åˆ›å»ºé¡¹ç›®äº‹ä»¶å¹¶åŠ è½½å†…å®¹"""
    # å…ˆæ‰§è¡Œåˆ›å»ºé¡¹ç›®çš„é€»è¾‘
    create_result = handle_create_project(project_path)
    project_path_result, status_html, log_msg = create_result

    # å¦‚æœåˆ›å»ºæˆåŠŸï¼ŒåŠ è½½å†…å®¹
    if "âœ…" in status_html or "âš ï¸" in status_html:
        # è°ƒç”¨æ–‡ä»¶è·¯å¾„å˜åŒ–å¤„ç†å‡½æ•°æ¥åŠ è½½å†…å®¹
        filepath_result = handle_filepath_change(project_path_result)

        # è¿”å›å®Œæ•´çš„ç»“æœ
        return (
            project_path_result,  # project_path_input
            status_html,          # project_status
            log_msg,              # log_output
            filepath_result[1],   # architecture_content
            filepath_result[2],   # blueprint_content
            filepath_result[3],   # chapter_content
            filepath_result[4],   # all_chapters_content
            filepath_result[5],   # character_content
            filepath_result[6],   # summary_content
            filepath_result[7],   # btn_step2
            filepath_result[8],   # btn_step3
            filepath_result[9],   # btn_step4
            filepath_result[10],  # chapter_selector
            filepath_result[11],  # single_chapter_content
            filepath_result[12],  # topic_input
            filepath_result[13],  # genre_input
            filepath_result[14],  # num_chapters_input
            filepath_result[15],  # word_number_input
            filepath_result[16],  # user_guidance_input
            filepath_result[17],  # characters_involved_input
            filepath_result[18],  # key_items_input
            filepath_result[19],  # scene_location_input
            filepath_result[20]   # time_constraint_input
        )
    else:
        # åˆ›å»ºå¤±è´¥ï¼Œè¿”å›ç©ºå†…å®¹
        return (
            project_path_result, status_html, log_msg,
            "", "", "", "", "", "",  # å†…å®¹ä¸ºç©º
            gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False),
            gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False),
            gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False),
            gr.Dropdown(choices=[], value=None), "",  # ç« èŠ‚é€‰æ‹©å™¨å’Œå†…å®¹ä¸ºç©º
            "", "ç„å¹»", 10, 3000, "", "", "", "", ""  # é»˜è®¤å°è¯´å‚æ•°
        )


def handle_load_project_and_load(project_path):
    """å¤„ç†åŠ è½½é¡¹ç›®äº‹ä»¶å¹¶åŠ è½½å†…å®¹"""
    # å…ˆæ‰§è¡ŒåŠ è½½é¡¹ç›®çš„é€»è¾‘
    load_result = handle_load_project(project_path)
    project_path_result, status_html, log_msg = load_result

    # å¦‚æœåŠ è½½æˆåŠŸï¼ŒåŠ è½½å†…å®¹
    if "âœ…" in status_html or "âš ï¸" in status_html:
        # è°ƒç”¨æ–‡ä»¶è·¯å¾„å˜åŒ–å¤„ç†å‡½æ•°æ¥åŠ è½½å†…å®¹
        filepath_result = handle_filepath_change(project_path_result)

        # è¿”å›å®Œæ•´çš„ç»“æœ
        return (
            project_path_result,  # project_path_input
            status_html,          # project_status
            log_msg,              # log_output
            filepath_result[1],   # architecture_content
            filepath_result[2],   # blueprint_content
            filepath_result[3],   # chapter_content
            filepath_result[4],   # all_chapters_content
            filepath_result[5],   # character_content
            filepath_result[6],   # summary_content
            filepath_result[7],   # btn_step2
            filepath_result[8],   # btn_step3
            filepath_result[9],   # btn_step4
            filepath_result[10],  # chapter_selector
            filepath_result[11],  # single_chapter_content
            filepath_result[12],  # topic_input
            filepath_result[13],  # genre_input
            filepath_result[14],  # num_chapters_input
            filepath_result[15],  # word_number_input
            filepath_result[16],  # user_guidance_input
            filepath_result[17],  # characters_involved_input
            filepath_result[18],  # key_items_input
            filepath_result[19],  # scene_location_input
            filepath_result[20]   # time_constraint_input
        )
    else:
        # åŠ è½½å¤±è´¥ï¼Œè¿”å›ç©ºå†…å®¹
        return (
            project_path_result, status_html, log_msg,
            "", "", "", "", "", "",  # å†…å®¹ä¸ºç©º
            gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False),
            gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False),
            gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False),
            gr.Dropdown(choices=[], value=None), "",  # ç« èŠ‚é€‰æ‹©å™¨å’Œå†…å®¹ä¸ºç©º
            "", "ç„å¹»", 10, 3000, "", "", "", "", ""  # é»˜è®¤å°è¯´å‚æ•°
        )


def handle_browse_folder():
    """å¤„ç†æ–‡ä»¶å¤¹æµè§ˆäº‹ä»¶"""
    try:
        # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼å¤„ç†æ–‡ä»¶å¤¹é€‰æ‹©
        import subprocess
        import platform

        system = platform.system()

        if system == "Darwin":  # macOS
            # ä½¿ç”¨osascriptè°ƒç”¨Finder
            result = subprocess.run([
                'osascript', '-e',
                'tell application "Finder" to set folder_path to choose folder with prompt "é€‰æ‹©å°è¯´é¡¹ç›®ç›®å½•"',
                '-e', 'return POSIX path of folder_path'
            ], capture_output=True, text=True, timeout=30)

            if result.returncode == 0:
                return result.stdout.strip()
            else:
                return ""

        elif system == "Windows":
            # Windowsä½¿ç”¨tkinter
            import tkinter as tk
            from tkinter import filedialog

            root = tk.Tk()
            root.withdraw()
            folder_path = filedialog.askdirectory(title="é€‰æ‹©å°è¯´é¡¹ç›®ç›®å½•")
            root.destroy()

            return folder_path if folder_path else ""

        else:
            # Linuxç­‰å…¶ä»–ç³»ç»Ÿ
            return "ğŸ’¡ è¯·æ‰‹åŠ¨è¾“å…¥é¡¹ç›®è·¯å¾„ï¼Œæˆ–ä½¿ç”¨ç³»ç»Ÿæ–‡ä»¶ç®¡ç†å™¨å¤åˆ¶è·¯å¾„"

    except subprocess.TimeoutExpired:
        return "â° æ–‡ä»¶å¤¹é€‰æ‹©è¶…æ—¶ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥è·¯å¾„"
    except Exception as e:
        return f"ğŸ’¡ è¯·æ‰‹åŠ¨è¾“å…¥é¡¹ç›®è·¯å¾„: {str(e)}"

def handle_save_config(llm_interface, llm_api_key, llm_base_url, llm_model, temperature, max_tokens, timeout,
                      embedding_interface, embedding_api_key, embedding_base_url, embedding_model, retrieval_k,
                      topic, genre, num_chapters, word_number, filepath, user_guidance,
                      characters_involved, key_items, scene_location, time_constraint):
    """å¤„ç†ä¿å­˜é…ç½®äº‹ä»¶"""
    llm_config = app.get_llm_config_from_form(
        llm_interface, llm_api_key, llm_base_url, llm_model, temperature, max_tokens, timeout
    )
    embedding_config = app.get_embedding_config_from_form(
        embedding_interface, embedding_api_key, embedding_base_url, embedding_model, retrieval_k
    )
    novel_params = {
        "topic": topic,
        "genre": genre,
        "num_chapters": num_chapters,
        "word_number": word_number,
        "filepath": filepath,
        "user_guidance": user_guidance,
        "characters_involved": characters_involved,
        "key_items": key_items,
        "scene_location": scene_location,
        "time_constraint": time_constraint
    }

    return app.save_config_to_file(llm_config, embedding_config, novel_params)

# å…¨å±€é…ç½®çŠ¶æ€è·Ÿè¸ª
config_status = {
    "llm_status": "æœªé…ç½®",
    "embedding_status": "æœªé…ç½®",
    "llm_timestamp": "",
    "embedding_timestamp": "",
    "llm_model": "",
    "embedding_model": ""
}

def generate_ai_status_monitor_html():
    """ç”ŸæˆAIçŠ¶æ€ç›‘æ§HTML"""
    import datetime
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # ç¡®å®šåˆ›ä½œå¤§è„‘çŠ¶æ€
    if config_status["llm_status"] == "æˆåŠŸ":
        llm_status_color = "#28a745"
        llm_status_text = "âœ… å·²å°±ç»ª"
        llm_model_info = config_status.get('llm_model', 'æœªçŸ¥æ¨¡å‹')
    elif config_status["llm_status"] == "å¤±è´¥":
        llm_status_color = "#dc3545"
        llm_status_text = "âŒ é…ç½®å¤±è´¥"
        llm_model_info = "éœ€è¦é‡æ–°é…ç½®"
    else:
        llm_status_color = "#ffc107"
        llm_status_text = "âš ï¸ å¾…é…ç½®"
        llm_model_info = "è¯·å…ˆé…ç½®AIæ¨¡å‹"

    # ç¡®å®šç†è§£å¼•æ“çŠ¶æ€
    if config_status["embedding_status"] == "æˆåŠŸ":
        embedding_status_color = "#28a745"
        embedding_status_text = "âœ… å·²å°±ç»ª"
        embedding_model_info = config_status.get('embedding_model', 'æœªçŸ¥æ¨¡å‹')
    elif config_status["embedding_status"] == "å¤±è´¥":
        embedding_status_color = "#dc3545"
        embedding_status_text = "âŒ é…ç½®å¤±è´¥"
        embedding_model_info = "éœ€è¦é‡æ–°é…ç½®"
    else:
        embedding_status_color = "#ffc107"
        embedding_status_text = "âš ï¸ å¾…é…ç½®"
        embedding_model_info = "è¯·å…ˆé…ç½®AIæ¨¡å‹"

    # ç¡®å®šæ•´ä½“çŠ¶æ€
    if config_status["llm_status"] == "æˆåŠŸ" and config_status["embedding_status"] == "æˆåŠŸ":
        overall_status = "ğŸš€ AIç³»ç»Ÿå·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹åˆ›ä½œ"
        overall_color = "#28a745"
    elif config_status["llm_status"] == "æˆåŠŸ" or config_status["embedding_status"] == "æˆåŠŸ":
        overall_status = "âš¡ éƒ¨åˆ†AIåŠŸèƒ½å¯ç”¨"
        overall_color = "#ffc107"
    else:
        overall_status = "âš ï¸ éœ€è¦é…ç½®AIæ¨¡å‹"
        overall_color = "#ffc107"

    return f"""
    <div style="background: #f8f9fa; border-radius: 12px; padding: 1rem; border-left: 4px solid {overall_color};">
        <h4 style="margin: 0 0 1rem 0; color: #333; display: flex; align-items: center; gap: 0.5rem;">
            ğŸ¤– AIçŠ¶æ€ç›‘æ§
        </h4>
        <div style="space-y: 0.5rem;">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                <span style="font-size: 0.9rem; color: #666;">åˆ›ä½œå¤§è„‘</span>
                <span style="font-size: 0.85rem; color: {llm_status_color}; font-weight: 500;">{llm_status_text}</span>
            </div>
            <div style="font-size: 0.8rem; color: #666; margin-bottom: 1rem;">{llm_model_info}</div>

            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                <span style="font-size: 0.9rem; color: #666;">ç†è§£å¼•æ“</span>
                <span style="font-size: 0.85rem; color: {embedding_status_color}; font-weight: 500;">{embedding_status_text}</span>
            </div>
            <div style="font-size: 0.8rem; color: #666; margin-bottom: 1rem;">{embedding_model_info}</div>

            <div style="text-align: center; padding: 0.75rem; background: rgba(255,255,255,0.7); border-radius: 8px; border: 1px solid {overall_color};">
                <div style="font-size: 0.9rem; color: {overall_color}; font-weight: 500;">{overall_status}</div>
            </div>
        </div>
    </div>
    """

def generate_config_status_html():
    """ç”Ÿæˆé…ç½®çŠ¶æ€HTML"""
    import datetime
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # ç¡®å®šLLMçŠ¶æ€
    if config_status["llm_status"] == "æˆåŠŸ":
        llm_indicator = "status-success"
        llm_text = f"LLM: å·²é…ç½® ({config_status['llm_model']})"
    elif config_status["llm_status"] == "å¤±è´¥":
        llm_indicator = "status-error"
        llm_text = "LLM: é…ç½®å¤±è´¥"
    else:
        llm_indicator = "status-warning"
        llm_text = "LLM: å¾…é…ç½®"

    # ç¡®å®šEmbeddingçŠ¶æ€
    if config_status["embedding_status"] == "æˆåŠŸ":
        embedding_indicator = "status-success"
        embedding_text = f"Embedding: å·²é…ç½® ({config_status['embedding_model']})"
    elif config_status["embedding_status"] == "å¤±è´¥":
        embedding_indicator = "status-error"
        embedding_text = "Embedding: é…ç½®å¤±è´¥"
    else:
        embedding_indicator = "status-warning"
        embedding_text = "Embedding: å¾…é…ç½®"

    # ç¡®å®šæœ€åæ›´æ–°æ—¶é—´
    if config_status["llm_timestamp"] or config_status["embedding_timestamp"]:
        last_update = max(config_status["llm_timestamp"], config_status["embedding_timestamp"])
    else:
        last_update = "ä»æœªé…ç½®"

    return f"""
    <div style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
                border-radius: 15px; padding: 1.5rem; margin-bottom: 1.5rem;
                border-left: 5px solid #ffc107; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
        <div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap;">
            <div>
                <h3 style="margin: 0 0 0.5rem 0; color: #333; font-size: 1.2rem;">ğŸ“Š é…ç½®çŠ¶æ€</h3>
                <div style="display: flex; gap: 2rem; flex-wrap: wrap;">
                    <div style="display: flex; align-items: center; gap: 0.5rem;">
                        <span class="status-indicator {llm_indicator}"></span>
                        <span style="font-weight: 500;">{llm_text}</span>
                    </div>
                    <div style="display: flex; align-items: center; gap: 0.5rem;">
                        <span class="status-indicator {embedding_indicator}"></span>
                        <span style="font-weight: 500;">{embedding_text}</span>
                    </div>
                    <div style="display: flex; align-items: center; gap: 0.5rem;">
                        <span class="status-indicator status-success"></span>
                        <span style="font-weight: 500;">ç³»ç»Ÿ: æ­£å¸¸</span>
                    </div>
                </div>
            </div>
            <div style="text-align: right;">
                <div style="font-size: 0.9rem; color: #666; margin-bottom: 0.5rem;">æœ€åæ›´æ–°</div>
                <div style="font-weight: 500; color: #333;">{last_update}</div>
            </div>
        </div>
    </div>
    """

def handle_test_llm_config(interface_format, api_key, base_url, model_name, temperature, max_tokens, timeout, current_log):
    """å¤„ç†æµ‹è¯•LLMé…ç½®äº‹ä»¶"""
    import datetime
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    full_timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    log_msg = current_log + f"\n[{timestamp}] ğŸ§ª å¼€å§‹æµ‹è¯•LLMé…ç½®...\n"
    log_msg += f"æ¥å£ç±»å‹: {interface_format}\n"
    log_msg += f"æ¨¡å‹åç§°: {model_name}\n"
    log_msg += f"Base URL: {base_url}\n"
    log_msg += f"Temperature: {temperature}\n"
    log_msg += f"Max Tokens: {max_tokens}\n"
    log_msg += f"Timeout: {timeout}ç§’\n"
    log_msg += "-" * 50 + "\n"

    success = False
    try:
        log_msg += "æ­£åœ¨åˆ›å»ºLLMé€‚é…å™¨...\n"
        llm_adapter = create_llm_adapter(
            interface_format=interface_format,
            base_url=base_url,
            model_name=model_name,
            api_key=api_key,
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=timeout
        )
        log_msg += "âœ… LLMé€‚é…å™¨åˆ›å»ºæˆåŠŸ\n"

        test_prompt = "Please reply 'OK'"
        log_msg += f"å‘é€æµ‹è¯•æç¤º: {test_prompt}\n"
        log_msg += "ç­‰å¾…æ¨¡å‹å“åº”...\n"

        response = llm_adapter.invoke(test_prompt)
        if response and response.strip():
            log_msg += f"âœ… LLMé…ç½®æµ‹è¯•æˆåŠŸï¼\n"
            log_msg += f"æ¨¡å‹å›å¤: {response}\n"
            log_msg += f"å›å¤é•¿åº¦: {len(response)} å­—ç¬¦\n"
            success = True

            # æ›´æ–°å…¨å±€çŠ¶æ€
            config_status["llm_status"] = "æˆåŠŸ"
            config_status["llm_timestamp"] = full_timestamp
            config_status["llm_model"] = f"{interface_format} {model_name}"
        else:
            log_msg += "âŒ LLMé…ç½®æµ‹è¯•å¤±è´¥ï¼šæœªè·å–åˆ°å“åº”\n"
            log_msg += "å¯èƒ½åŸå› ï¼š\n"
            log_msg += "1. APIå¯†é’¥æ— æ•ˆ\n"
            log_msg += "2. ç½‘ç»œè¿æ¥é—®é¢˜\n"
            log_msg += "3. æ¨¡å‹åç§°é”™è¯¯\n"
            log_msg += "4. æœåŠ¡å™¨æš‚æ—¶ä¸å¯ç”¨\n"

            # æ›´æ–°å…¨å±€çŠ¶æ€
            config_status["llm_status"] = "å¤±è´¥"
            config_status["llm_timestamp"] = full_timestamp
            config_status["llm_model"] = f"{interface_format} {model_name}"

    except Exception as e:
        log_msg += f"âŒ LLMé…ç½®æµ‹è¯•å‡ºé”™: {str(e)}\n"
        log_msg += "è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n"
        import traceback
        log_msg += traceback.format_exc() + "\n"

        # æ›´æ–°å…¨å±€çŠ¶æ€
        config_status["llm_status"] = "å¤±è´¥"
        config_status["llm_timestamp"] = full_timestamp
        config_status["llm_model"] = f"{interface_format} {model_name}"

    log_msg += "=" * 50 + "\n"

    # ç”ŸæˆçŠ¶æ€HTML
    if success:
        status_html = f"""
        <div style="margin: 1rem 0; padding: 0.75rem; background: #d4edda;
                    border-radius: 8px; border-left: 3px solid #28a745; display: flex; align-items: center;">
            <div style="margin-right: 0.5rem; font-size: 1.2rem;">âœ…</div>
            <div>
                <div style="font-weight: 500; color: #155724;">æµ‹è¯•æˆåŠŸ</div>
                <div style="font-size: 0.85rem; color: #155724;">
                    {interface_format} {model_name} è¿æ¥æ­£å¸¸ | {timestamp}
                </div>
            </div>
        </div>
        """
    else:
        status_html = """
        <div style="margin: 1rem 0; padding: 0.75rem; background: #f8d7da;
                    border-radius: 8px; border-left: 3px solid #dc3545; display: flex; align-items: center;">
            <div style="margin-right: 0.5rem; font-size: 1.2rem;">âŒ</div>
            <div>
                <div style="font-weight: 500; color: #721c24;">æµ‹è¯•å¤±è´¥</div>
                <div style="font-size: 0.85rem; color: #721c24;">è¯·æ£€æŸ¥é…ç½®å‚æ•°å’Œç½‘ç»œè¿æ¥</div>
            </div>
        </div>
        """

    # ç”Ÿæˆæ›´æ–°çš„é…ç½®çŠ¶æ€HTML
    config_status_html = generate_config_status_html()



    return log_msg, status_html, config_status_html

def handle_test_embedding_config(interface_format, api_key, base_url, model_name, current_log, use_same_key, llm_api_key, llm_base_url):
    """å¤„ç†æµ‹è¯•Embeddingé…ç½®äº‹ä»¶"""
    import datetime
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    full_timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # å¦‚æœé€‰æ‹©ä½¿ç”¨ç›¸åŒå¯†é’¥ï¼Œåˆ™ä½¿ç”¨LLMçš„é…ç½®
    if use_same_key:
        actual_api_key = llm_api_key
        actual_base_url = llm_base_url
        log_msg = current_log + f"\n[{timestamp}] ğŸ” å¼€å§‹æµ‹è¯•Embeddingé…ç½®...\n"
        log_msg += f"ğŸ”— ä½¿ç”¨LLMç›¸åŒé…ç½®\n"
        log_msg += f"æ¥å£ç±»å‹: {interface_format}\n"
        log_msg += f"æ¨¡å‹åç§°: {model_name}\n"
        log_msg += f"Base URL: {actual_base_url} (æ¥è‡ªLLMé…ç½®)\n"
        log_msg += f"API Key: {'***' if actual_api_key else 'æœªè®¾ç½®'} (æ¥è‡ªLLMé…ç½®)\n"
    else:
        actual_api_key = api_key
        actual_base_url = base_url
        log_msg = current_log + f"\n[{timestamp}] ğŸ” å¼€å§‹æµ‹è¯•Embeddingé…ç½®...\n"
        log_msg += f"ğŸ”§ ä½¿ç”¨ç‹¬ç«‹é…ç½®\n"
        log_msg += f"æ¥å£ç±»å‹: {interface_format}\n"
        log_msg += f"æ¨¡å‹åç§°: {model_name}\n"
        log_msg += f"Base URL: {actual_base_url}\n"
        log_msg += f"API Key: {'***' if actual_api_key else 'æœªè®¾ç½®'}\n"

    log_msg += "-" * 50 + "\n"

    success = False
    try:
        log_msg += "æ­£åœ¨åˆ›å»ºEmbeddingé€‚é…å™¨...\n"
        embedding_adapter = create_embedding_adapter(
            interface_format=interface_format,
            api_key=actual_api_key,
            base_url=actual_base_url,
            model_name=model_name
        )
        log_msg += "âœ… Embeddingé€‚é…å™¨åˆ›å»ºæˆåŠŸ\n"

        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        log_msg += f"æµ‹è¯•æ–‡æœ¬: {test_text}\n"
        log_msg += "æ­£åœ¨ç”Ÿæˆå‘é‡...\n"

        embeddings = embedding_adapter.embed_query(test_text)
        if embeddings and len(embeddings) > 0:
            log_msg += f"âœ… Embeddingé…ç½®æµ‹è¯•æˆåŠŸï¼\n"
            log_msg += f"ç”Ÿæˆçš„å‘é‡ç»´åº¦: {len(embeddings)}\n"
            log_msg += f"å‘é‡å‰5ä¸ªå€¼: {embeddings[:5]}\n"
            success = True

            # æ›´æ–°å…¨å±€çŠ¶æ€
            config_status["embedding_status"] = "æˆåŠŸ"
            config_status["embedding_timestamp"] = full_timestamp
            config_status["embedding_model"] = f"{interface_format} {model_name}"
        else:
            log_msg += "âŒ Embeddingé…ç½®æµ‹è¯•å¤±è´¥ï¼šæœªè·å–åˆ°å‘é‡\n"
            log_msg += "å¯èƒ½åŸå› ï¼š\n"
            log_msg += "1. APIå¯†é’¥æ— æ•ˆ\n"
            log_msg += "2. æ¨¡å‹åç§°é”™è¯¯\n"
            log_msg += "3. ç½‘ç»œè¿æ¥é—®é¢˜\n"
            log_msg += "4. æœåŠ¡ä¸æ”¯æŒè¯¥æ¨¡å‹\n"

            # æ›´æ–°å…¨å±€çŠ¶æ€
            config_status["embedding_status"] = "å¤±è´¥"
            config_status["embedding_timestamp"] = full_timestamp
            config_status["embedding_model"] = f"{interface_format} {model_name}"

    except Exception as e:
        log_msg += f"âŒ Embeddingé…ç½®æµ‹è¯•å‡ºé”™: {str(e)}\n"
        log_msg += "è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n"
        import traceback
        log_msg += traceback.format_exc() + "\n"

        # æ›´æ–°å…¨å±€çŠ¶æ€
        config_status["embedding_status"] = "å¤±è´¥"
        config_status["embedding_timestamp"] = full_timestamp
        config_status["embedding_model"] = f"{interface_format} {model_name}"

    log_msg += "=" * 50 + "\n"

    # ç”ŸæˆçŠ¶æ€HTML
    if success:
        status_html = f"""
        <div style="margin: 1rem 0; padding: 0.75rem; background: #d4edda;
                    border-radius: 8px; border-left: 3px solid #28a745; display: flex; align-items: center;">
            <div style="margin-right: 0.5rem; font-size: 1.2rem;">âœ…</div>
            <div>
                <div style="font-weight: 500; color: #155724;">æµ‹è¯•æˆåŠŸ</div>
                <div style="font-size: 0.85rem; color: #155724;">
                    {interface_format} {model_name} è¿æ¥æ­£å¸¸ | {timestamp}
                </div>
            </div>
        </div>
        """
    else:
        status_html = """
        <div style="margin: 1rem 0; padding: 0.75rem; background: #f8d7da;
                    border-radius: 8px; border-left: 3px solid #dc3545; display: flex; align-items: center;">
            <div style="margin-right: 0.5rem; font-size: 1.2rem;">âŒ</div>
            <div>
                <div style="font-weight: 500; color: #721c24;">æµ‹è¯•å¤±è´¥</div>
                <div style="font-size: 0.85rem; color: #721c24;">è¯·æ£€æŸ¥é…ç½®å‚æ•°å’Œç½‘ç»œè¿æ¥</div>
            </div>
        </div>
        """

    # ç”Ÿæˆæ›´æ–°çš„é…ç½®çŠ¶æ€HTML
    config_status_html = generate_config_status_html()

    return log_msg, status_html, config_status_html

def handle_clear_config_log():
    """æ¸…ç©ºé…ç½®æ—¥å¿—"""
    import datetime
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")

    # é‡ç½®å…¨å±€é…ç½®çŠ¶æ€
    config_status["llm_status"] = "æœªé…ç½®"
    config_status["embedding_status"] = "æœªé…ç½®"
    config_status["llm_timestamp"] = ""
    config_status["embedding_timestamp"] = ""
    config_status["llm_model"] = ""
    config_status["embedding_model"] = ""

    # é‡ç½®çŠ¶æ€HTML
    reset_status_html = """
    <div style="margin: 1rem 0; padding: 0.75rem; background: #fff3cd;
                border-radius: 8px; border-left: 3px solid #ffc107; display: flex; align-items: center;">
        <div style="margin-right: 0.5rem; font-size: 1.2rem;">âš ï¸</div>
        <div>
            <div style="font-weight: 500; color: #856404;">æœªæµ‹è¯•</div>
            <div style="font-size: 0.85rem; color: #856404;">è¯·å…ˆæµ‹è¯•é…ç½®ç¡®ä¿è¿æ¥æ­£å¸¸</div>
        </div>
    </div>
    """

    # ç”Ÿæˆé‡ç½®çš„é…ç½®çŠ¶æ€HTML
    config_status_html = generate_config_status_html()

    return f"[{timestamp}] ğŸ“‹ é…ç½®æµ‹è¯•æ—¥å¿—å·²æ¸…ç©º\n", reset_status_html, reset_status_html, config_status_html

def handle_load_file(filepath, filename):
    """å¤„ç†æ–‡ä»¶åŠ è½½äº‹ä»¶"""
    if not filepath:
        return "", "âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„"

    full_path = os.path.join(filepath, filename)
    content = read_file(full_path)
    if content:
        return content, f"âœ… å·²åŠ è½½ {filename}"
    else:
        return "", f"âŒ æ— æ³•åŠ è½½ {filename}"

def handle_save_file(filepath, filename, content):
    """å¤„ç†æ–‡ä»¶ä¿å­˜äº‹ä»¶"""
    if not filepath:
        return "âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„"

    full_path = os.path.join(filepath, filename)
    try:
        clear_file_content(full_path)
        save_string_to_txt(content, full_path)
        return f"âœ… å·²ä¿å­˜ {filename}"
    except Exception as e:
        return f"âŒ ä¿å­˜ {filename} æ—¶å‡ºé”™: {str(e)}"

# æ ¸å¿ƒç”ŸæˆåŠŸèƒ½å¤„ç†å‡½æ•°
def handle_generate_architecture(llm_interface, llm_api_key, llm_base_url, llm_model, temperature, max_tokens, timeout,
                                topic, genre, num_chapters, word_number, filepath, user_guidance, current_log):
    """å¤„ç†ç”Ÿæˆå°è¯´æ¶æ„äº‹ä»¶"""
    import os
    from utils import read_file

    if not filepath:
        return (
            current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„"),
            "",  # architecture_content
            gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False)  # btn_step2
        )

    if not topic.strip():
        return (
            current_log + app.log_message("âŒ è¯·å…ˆè¾“å…¥å°è¯´ä¸»é¢˜"),
            "",  # architecture_content
            gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False)  # btn_step2
        )

    try:
        log_msg = current_log + app.log_message("ğŸš€ å¼€å§‹ç”Ÿæˆå°è¯´æ¶æ„...")

        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œç”Ÿæˆ
        def generate_task():
            try:
                Novel_architecture_generate(
                    interface_format=llm_interface,
                    api_key=llm_api_key,
                    base_url=llm_base_url,
                    llm_model=llm_model,
                    topic=topic,
                    genre=genre,
                    number_of_chapters=int(num_chapters),
                    word_number=int(word_number),
                    filepath=filepath,
                    user_guidance=user_guidance,
                    temperature=temperature,
                    max_tokens=int(max_tokens),
                    timeout=int(timeout)
                )
                return "âœ… å°è¯´æ¶æ„ç”Ÿæˆå®Œæˆï¼"
            except Exception as e:
                return f"âŒ ç”Ÿæˆå°è¯´æ¶æ„æ—¶å‡ºé”™: {str(e)}"

        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä½¿ç”¨å¼‚æ­¥æˆ–è¿›åº¦æ¡
        result = generate_task()
        final_log = log_msg + app.log_message(result)

        # è¯»å–ç”Ÿæˆçš„æ¶æ„å†…å®¹
        architecture_file = os.path.join(filepath, "Novel_architecture.txt")
        if os.path.exists(architecture_file) and "âœ…" in result:
            architecture_content = read_file(architecture_file)
            # å¯ç”¨ä¸‹ä¸€æ­¥æŒ‰é’®
            next_button = gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="primary", interactive=True)
        else:
            architecture_content = ""
            next_button = gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False)

        return final_log, architecture_content, next_button

    except Exception as e:
        return (
            current_log + app.log_message(f"âŒ ç”Ÿæˆå°è¯´æ¶æ„æ—¶å‡ºé”™: {str(e)}"),
            "",  # architecture_content
            gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False)  # btn_step2
        )

def handle_generate_blueprint(llm_interface, llm_api_key, llm_base_url, llm_model, temperature, max_tokens, timeout,
                             filepath, num_chapters, user_guidance, current_log):
    """å¤„ç†ç”Ÿæˆç« èŠ‚è“å›¾äº‹ä»¶"""
    import os
    from utils import read_file

    if not filepath:
        return (
            current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„"),
            "",  # blueprint_content
            gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False)  # btn_step3
        )

    try:
        log_msg = current_log + app.log_message("ğŸš€ å¼€å§‹ç”Ÿæˆç« èŠ‚è“å›¾...")

        def generate_task():
            try:
                Chapter_blueprint_generate(
                    interface_format=llm_interface,
                    api_key=llm_api_key,
                    base_url=llm_base_url,
                    llm_model=llm_model,
                    filepath=filepath,
                    number_of_chapters=int(num_chapters),
                    user_guidance=user_guidance,
                    temperature=temperature,
                    max_tokens=int(max_tokens),
                    timeout=int(timeout)
                )
                return "âœ… ç« èŠ‚è“å›¾ç”Ÿæˆå®Œæˆï¼"
            except Exception as e:
                return f"âŒ ç”Ÿæˆç« èŠ‚è“å›¾æ—¶å‡ºé”™: {str(e)}"

        result = generate_task()
        final_log = log_msg + app.log_message(result)

        # è¯»å–ç”Ÿæˆçš„è“å›¾å†…å®¹
        blueprint_file = os.path.join(filepath, "Novel_directory.txt")
        if os.path.exists(blueprint_file) and "âœ…" in result:
            blueprint_content = read_file(blueprint_file)
            # å¯ç”¨ä¸‹ä¸€æ­¥æŒ‰é’®
            next_button = gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="primary", interactive=True)
        else:
            blueprint_content = ""
            next_button = gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False)

        return final_log, blueprint_content, next_button

    except Exception as e:
        return (
            current_log + app.log_message(f"âŒ ç”Ÿæˆç« èŠ‚è“å›¾æ—¶å‡ºé”™: {str(e)}"),
            "",  # blueprint_content
            gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False)  # btn_step3
        )

def handle_generate_chapter_draft(llm_interface, llm_api_key, llm_base_url, llm_model, temperature, max_tokens, timeout,
                                 embedding_interface, embedding_api_key, embedding_base_url, embedding_model, retrieval_k,
                                 filepath, chapter_num, word_number, user_guidance, current_log):
    """å¤„ç†ç”Ÿæˆç« èŠ‚è‰ç¨¿äº‹ä»¶"""
    import os
    from utils import read_file

    if not filepath:
        return (
            "",  # chapter_content
            "",  # all_chapters_content
            current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„"),
            gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False),  # btn_step4
            chapter_num,  # current_chapter (ä¿æŒåŸå€¼)
            gr.Dropdown(choices=[], value=None)  # chapter_selector
        )

    try:
        log_msg = current_log + app.log_message(f"ğŸš€ å¼€å§‹ç”Ÿæˆç¬¬{chapter_num}ç« è‰ç¨¿...")

        def generate_task():
            try:
                result = generate_chapter_draft(
                    interface_format=llm_interface,
                    api_key=llm_api_key,
                    base_url=llm_base_url,
                    model_name=llm_model,
                    embedding_interface_format=embedding_interface,
                    embedding_api_key=embedding_api_key,
                    embedding_url=embedding_base_url,
                    embedding_model_name=embedding_model,
                    embedding_retrieval_k=int(retrieval_k),
                    filepath=filepath,
                    novel_number=int(chapter_num),
                    word_number=int(word_number),
                    user_guidance=user_guidance,
                    characters_involved="",  # ä»ç« èŠ‚è“å›¾ä¸­è‡ªåŠ¨è·å–
                    key_items="",  # ä»ç« èŠ‚è“å›¾ä¸­è‡ªåŠ¨è·å–
                    scene_location="",  # ä»ç« èŠ‚è“å›¾ä¸­è‡ªåŠ¨è·å–
                    time_constraint="",  # ä»ç« èŠ‚è“å›¾ä¸­è‡ªåŠ¨è·å–
                    temperature=temperature,
                    max_tokens=int(max_tokens),
                    timeout=int(timeout)
                )

                # è¯»å–ç”Ÿæˆçš„ç« èŠ‚å†…å®¹
                chapter_file = os.path.join(filepath, "chapters", f"chapter_{chapter_num}.txt")
                chapter_content = read_file(chapter_file)

                # è®¾ç½®ç« èŠ‚çŠ¶æ€ä¸ºè‰ç¨¿
                set_chapter_status(filepath, int(chapter_num), "è‰ç¨¿")

                return chapter_content, "âœ… ç« èŠ‚è‰ç¨¿ç”Ÿæˆå®Œæˆï¼"
            except Exception as e:
                return "", f"âŒ ç”Ÿæˆç« èŠ‚è‰ç¨¿æ—¶å‡ºé”™: {str(e)}"

        chapter_content, result_msg = generate_task()
        final_log = log_msg + app.log_message(result_msg)

        # åŠ è½½æ‰€æœ‰ç« èŠ‚å†…å®¹
        all_chapters = load_all_chapters(filepath)

        # æ›´æ–°ç« èŠ‚é€‰æ‹©å™¨
        chapter_list = get_chapter_list(filepath)
        current_chapter_display = f"ç¬¬{chapter_num}ç«  ğŸ“"  # æ–°ç”Ÿæˆçš„æ˜¯è‰ç¨¿
        chapter_selector_update = gr.Dropdown(choices=chapter_list, value=current_chapter_display)

        # å¦‚æœç”ŸæˆæˆåŠŸï¼Œå¯ç”¨ç¬¬å››æ­¥æŒ‰é’®
        if chapter_content and "âœ…" in result_msg:
            next_button = gr.Button("âœ… å†…å®¹å®šç¨¿", variant="primary", interactive=True)
        else:
            next_button = gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False)

        return chapter_content, all_chapters, final_log, next_button, chapter_num, chapter_selector_update

    except Exception as e:
        return (
            "",  # chapter_content
            "",  # all_chapters_content
            current_log + app.log_message(f"âŒ ç”Ÿæˆç« èŠ‚è‰ç¨¿æ—¶å‡ºé”™: {str(e)}"),
            gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False),  # btn_step4
            chapter_num,  # current_chapter (ä¿æŒåŸå€¼)
            gr.Dropdown(choices=get_chapter_list(filepath), value=None)  # chapter_selector
        )

def handle_finalize_chapter(llm_interface, llm_api_key, llm_base_url, llm_model, temperature, max_tokens, timeout,
                           embedding_interface, embedding_api_key, embedding_base_url, embedding_model,
                           filepath, chapter_num, word_number, chapter_content, current_log):
    """å¤„ç†å®šç¨¿ç« èŠ‚äº‹ä»¶"""
    import os
    from utils import read_file, save_string_to_txt

    if not filepath:
        return (
            current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„"),
            "",  # character_content
            "",  # summary_content
            chapter_num,  # current_chapter (ä¿æŒåŸå€¼)
            gr.Dropdown(choices=[], value=None)  # chapter_selector
        )

    if not chapter_content.strip():
        return (
            current_log + app.log_message("âŒ ç« èŠ‚å†…å®¹ä¸ºç©ºï¼Œæ— æ³•å®šç¨¿"),
            "",  # character_content
            "",  # summary_content
            chapter_num,  # current_chapter (ä¿æŒåŸå€¼)
            gr.Dropdown(choices=get_chapter_list(filepath), value=None)  # chapter_selector
        )

    try:
        log_msg = current_log + app.log_message(f"ğŸš€ å¼€å§‹å®šç¨¿ç¬¬{chapter_num}ç« ...")

        # å…ˆä¿å­˜å½“å‰ç« èŠ‚å†…å®¹
        chapter_file = os.path.join(filepath, "chapters", f"chapter_{chapter_num}.txt")
        # ç¡®ä¿chaptersç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(chapter_file), exist_ok=True)
        save_string_to_txt(chapter_content, chapter_file)

        def finalize_task():
            try:
                finalize_chapter(
                    interface_format=llm_interface,
                    api_key=llm_api_key,
                    base_url=llm_base_url,
                    model_name=llm_model,
                    embedding_interface_format=embedding_interface,
                    embedding_api_key=embedding_api_key,
                    embedding_url=embedding_base_url,
                    embedding_model_name=embedding_model,
                    filepath=filepath,
                    novel_number=int(chapter_num),
                    word_number=int(word_number),
                    temperature=temperature,
                    max_tokens=int(max_tokens),
                    timeout=int(timeout)
                )
                return "âœ… ç« èŠ‚å®šç¨¿å®Œæˆï¼å·²æ›´æ–°å…¨å±€æ‘˜è¦ã€è§’è‰²çŠ¶æ€å’Œå‘é‡åº“ã€‚"
            except Exception as e:
                return f"âŒ å®šç¨¿ç« èŠ‚æ—¶å‡ºé”™: {str(e)}"

        result = finalize_task()
        final_log = log_msg + app.log_message(result)

        # è¯»å–æ›´æ–°åçš„è§’è‰²çŠ¶æ€å’Œå…¨å±€æ‘˜è¦
        character_file = os.path.join(filepath, "character_state.txt")
        summary_file = os.path.join(filepath, "global_summary.txt")

        character_content = ""
        summary_content = ""
        next_chapter_num = chapter_num  # é»˜è®¤ä¿æŒå½“å‰ç« èŠ‚å·

        if "âœ…" in result:
            if os.path.exists(character_file):
                character_content = read_file(character_file)
            if os.path.exists(summary_file):
                summary_content = read_file(summary_file)
            # å®šç¨¿æˆåŠŸåï¼Œè®¾ç½®ç« èŠ‚çŠ¶æ€ä¸ºå·²å®šç¨¿
            set_chapter_status(filepath, int(chapter_num), "å·²å®šç¨¿")
            # è‡ªåŠ¨å°†å½“å‰ç« èŠ‚å·å¢åŠ 1ï¼Œå‡†å¤‡ä¸‹ä¸€ç« 
            next_chapter_num = int(chapter_num) + 1

        # æ›´æ–°ç« èŠ‚é€‰æ‹©å™¨
        chapter_list = get_chapter_list(filepath)
        chapter_selector_update = gr.Dropdown(choices=chapter_list, value=None)

        return final_log, character_content, summary_content, next_chapter_num, chapter_selector_update

    except Exception as e:
        return (
            current_log + app.log_message(f"âŒ å®šç¨¿ç« èŠ‚æ—¶å‡ºé”™: {str(e)}"),
            "",  # character_content
            "",  # summary_content
            chapter_num,  # current_chapter (ä¿æŒåŸå€¼)
            gr.Dropdown(choices=get_chapter_list(filepath), value=None)  # chapter_selector
        )

# è¾…åŠ©åŠŸèƒ½å¤„ç†å‡½æ•°
def handle_consistency_check(llm_interface, llm_api_key, llm_base_url, llm_model, temperature, max_tokens, timeout,
                            filepath, chapter_num, current_log):
    """å¤„ç†ä¸€è‡´æ€§æ£€æŸ¥äº‹ä»¶"""
    if not filepath:
        return current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„")

    try:
        log_msg = current_log + app.log_message(f"ğŸ” å¼€å§‹æ£€æŸ¥ç¬¬{chapter_num}ç« çš„ä¸€è‡´æ€§...")

        def check_task():
            try:
                # è¯»å–å¿…è¦çš„æ–‡ä»¶å†…å®¹
                chap_file = os.path.join(filepath, "chapters", f"chapter_{chapter_num}.txt")
                chapter_text = read_file(chap_file)

                if not chapter_text.strip():
                    return "âš ï¸ å½“å‰ç« èŠ‚æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥ã€‚"

                # è¯»å–å…¶ä»–å¿…è¦æ–‡ä»¶
                novel_setting_file = os.path.join(filepath, "Novel_architecture.txt")
                novel_setting = read_file(novel_setting_file)

                character_state_file = os.path.join(filepath, "character_state.txt")
                character_state = read_file(character_state_file)

                global_summary_file = os.path.join(filepath, "global_summary.txt")
                global_summary = read_file(global_summary_file)

                # è°ƒç”¨ä¸€è‡´æ€§æ£€æŸ¥å‡½æ•°
                result = check_consistency(
                    novel_setting=novel_setting,
                    character_state=character_state,
                    global_summary=global_summary,
                    chapter_text=chapter_text,
                    api_key=llm_api_key,
                    base_url=llm_base_url,
                    model_name=llm_model,
                    temperature=temperature,
                    interface_format=llm_interface,
                    max_tokens=int(max_tokens),
                    timeout=int(timeout),
                    plot_arcs=""  # å¯ä»¥åç»­æ‰©å±•è¯»å–å‰§æƒ…è¦ç‚¹æ–‡ä»¶
                )
                return f"âœ… ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼\n{result}"
            except Exception as e:
                return f"âŒ ä¸€è‡´æ€§æ£€æŸ¥æ—¶å‡ºé”™: {str(e)}"

        result = check_task()
        return log_msg + app.log_message(result)

    except Exception as e:
        return current_log + app.log_message(f"âŒ ä¸€è‡´æ€§æ£€æŸ¥æ—¶å‡ºé”™: {str(e)}")

def handle_import_knowledge(filepath, current_log):
    """å¤„ç†å¯¼å…¥çŸ¥è¯†åº“äº‹ä»¶"""
    if not filepath:
        return current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„")

    try:
        log_msg = current_log + app.log_message("ğŸ“š å¼€å§‹å¯¼å…¥çŸ¥è¯†åº“...")

        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æä¾›æ–‡ä»¶é€‰æ‹©ç•Œé¢
        knowledge_file = os.path.join(filepath, "knowledge.txt")
        if os.path.exists(knowledge_file):
            import_knowledge_file(knowledge_file, filepath)
            return log_msg + app.log_message("âœ… çŸ¥è¯†åº“å¯¼å…¥å®Œæˆï¼")
        else:
            return log_msg + app.log_message(f"âŒ æœªæ‰¾åˆ°çŸ¥è¯†åº“æ–‡ä»¶: {knowledge_file}")

    except Exception as e:
        return current_log + app.log_message(f"âŒ å¯¼å…¥çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")

def handle_clear_vectorstore(filepath, current_log):
    """å¤„ç†æ¸…ç©ºå‘é‡åº“äº‹ä»¶"""
    if not filepath:
        return current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„")

    try:
        log_msg = current_log + app.log_message("ğŸ—‘ï¸ å¼€å§‹æ¸…ç©ºå‘é‡åº“...")
        clear_vector_store(filepath)
        return log_msg + app.log_message("âœ… å‘é‡åº“å·²æ¸…ç©ºï¼")

    except Exception as e:
        return current_log + app.log_message(f"âŒ æ¸…ç©ºå‘é‡åº“æ—¶å‡ºé”™: {str(e)}")

def handle_show_plot_arcs(filepath, current_log):
    """å¤„ç†æŸ¥çœ‹å‰§æƒ…è¦ç‚¹äº‹ä»¶"""
    if not filepath:
        return current_log + app.log_message("âŒ è¯·å…ˆè®¾ç½®ä¿å­˜æ–‡ä»¶è·¯å¾„")

    try:
        plot_arcs_file = os.path.join(filepath, "plot_arcs.txt")
        content = read_file(plot_arcs_file)
        if content:
            return current_log + app.log_message(f"ğŸ“– å‰§æƒ…è¦ç‚¹å†…å®¹ï¼š\n{content}")
        else:
            return current_log + app.log_message("âŒ æœªæ‰¾åˆ°å‰§æƒ…è¦ç‚¹æ–‡ä»¶")

    except Exception as e:
        return current_log + app.log_message(f"âŒ æŸ¥çœ‹å‰§æƒ…è¦ç‚¹æ—¶å‡ºé”™: {str(e)}")

# æ–‡ä»¶çŠ¶æ€æ£€æŸ¥å’Œç•Œé¢åˆå§‹åŒ–å‡½æ•°
def check_file_status_and_init_ui(filepath):
    """æ£€æŸ¥æ–‡ä»¶çŠ¶æ€å¹¶è¿”å›åˆå§‹åŒ–çš„UIçŠ¶æ€"""
    import os
    from utils import read_file

    if not filepath or not os.path.exists(filepath):
        return {
            'architecture_content': "",
            'blueprint_content': "",
            'chapter_content': "",
            'character_content': "",
            'summary_content': "",
            'btn_step2_state': gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False),
            'btn_step3_state': gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False),
            'btn_step4_state': gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False),
            'log_message': "ğŸ“ è¯·è®¾ç½®ä¿å­˜è·¯å¾„åï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ£€æŸ¥å·²æœ‰æ–‡ä»¶å¹¶æ¢å¤è¿›åº¦ã€‚"
        }

    result = {
        'architecture_content': "",
        'blueprint_content': "",
        'chapter_content': "",
        'character_content': "",
        'summary_content': "",
        'btn_step2_state': gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="secondary", interactive=False),
        'btn_step3_state': gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="secondary", interactive=False),
        'btn_step4_state': gr.Button("âœ… å†…å®¹å®šç¨¿", variant="secondary", interactive=False),
        'log_message': ""
    }

    messages = []

    # æ£€æŸ¥æ¶æ„æ–‡ä»¶
    arch_file = os.path.join(filepath, "Novel_architecture.txt")
    if os.path.exists(arch_file):
        result['architecture_content'] = read_file(arch_file)
        result['btn_step2_state'] = gr.Button("ğŸ“‘ ç”Ÿæˆç›®å½•", variant="primary", interactive=True)
        messages.append("âœ… å·²åŠ è½½å°è¯´æ¶æ„")

    # æ£€æŸ¥ç›®å½•æ–‡ä»¶
    blueprint_file = os.path.join(filepath, "Novel_directory.txt")
    if os.path.exists(blueprint_file):
        result['blueprint_content'] = read_file(blueprint_file)
        result['btn_step3_state'] = gr.Button("ğŸ“ ç”Ÿæˆç« èŠ‚", variant="primary", interactive=True)
        messages.append("âœ… å·²åŠ è½½ç« èŠ‚ç›®å½•")

    # æ£€æŸ¥è§’è‰²çŠ¶æ€æ–‡ä»¶
    character_file = os.path.join(filepath, "character_state.txt")
    if os.path.exists(character_file):
        result['character_content'] = read_file(character_file)
        messages.append("âœ… å·²åŠ è½½è§’è‰²çŠ¶æ€")

    # æ£€æŸ¥å…¨å±€æ‘˜è¦æ–‡ä»¶
    summary_file = os.path.join(filepath, "global_summary.txt")
    if os.path.exists(summary_file):
        result['summary_content'] = read_file(summary_file)
        messages.append("âœ… å·²åŠ è½½å…¨å±€æ‘˜è¦")

    # æ£€æŸ¥æ˜¯å¦æœ‰ç« èŠ‚æ–‡ä»¶ï¼ˆæ£€æŸ¥chaptersç›®å½•ä¸‹æ˜¯å¦æœ‰ä»»ä½•ç« èŠ‚æ–‡ä»¶ï¼‰
    chapters_dir = os.path.join(filepath, "chapters")
    if os.path.exists(chapters_dir):
        # æŸ¥æ‰¾æœ€æ–°çš„ç« èŠ‚æ–‡ä»¶
        chapter_files = [f for f in os.listdir(chapters_dir) if f.startswith("chapter_") and f.endswith(".txt")]
        if chapter_files:
            # æŒ‰ç« èŠ‚å·æ’åºï¼Œå–æœ€æ–°çš„
            chapter_numbers = []
            for f in chapter_files:
                try:
                    num = int(f.replace("chapter_", "").replace(".txt", ""))
                    chapter_numbers.append(num)
                except ValueError:
                    continue

            if chapter_numbers:
                latest_chapter = max(chapter_numbers)
                latest_chapter_file = os.path.join(chapters_dir, f"chapter_{latest_chapter}.txt")
                result['chapter_content'] = read_file(latest_chapter_file)
                result['btn_step4_state'] = gr.Button("âœ… å†…å®¹å®šç¨¿", variant="primary", interactive=True)
                messages.append(f"âœ… å·²åŠ è½½ç¬¬{latest_chapter}ç« å†…å®¹")

    if messages:
        result['log_message'] = "ğŸ”„ æ¢å¤åˆ›ä½œè¿›åº¦ï¼š\n" + "\n".join(messages)
    else:
        result['log_message'] = "ğŸ“ æœªå‘ç°å·²æœ‰æ–‡ä»¶ï¼Œå¯ä»¥å¼€å§‹æ–°çš„åˆ›ä½œã€‚"

    return result

def load_all_chapters(filepath):
    """åŠ è½½æ‰€æœ‰ç« èŠ‚å†…å®¹ï¼ŒåŒ…å«çŠ¶æ€ä¿¡æ¯"""
    if not filepath:
        return ""

    chapters_dir = os.path.join(filepath, "chapters")
    if not os.path.exists(chapters_dir):
        return ""

    # è·å–æ‰€æœ‰ç« èŠ‚æ–‡ä»¶
    chapter_files = [f for f in os.listdir(chapters_dir) if f.startswith("chapter_") and f.endswith(".txt")]
    if not chapter_files:
        return ""

    # æŒ‰ç« èŠ‚å·æ’åº
    chapter_numbers = []
    for f in chapter_files:
        try:
            num = int(f.replace("chapter_", "").replace(".txt", ""))
            chapter_numbers.append(num)
        except ValueError:
            continue

    chapter_numbers.sort()

    # è¯»å–æ‰€æœ‰ç« èŠ‚å†…å®¹
    all_content = []
    for num in chapter_numbers:
        chapter_file = os.path.join(chapters_dir, f"chapter_{num}.txt")
        content = read_file(chapter_file)
        if content:
            status = get_chapter_status(filepath, num)
            status_icon = "âœ…" if status == "å·²å®šç¨¿" else "ğŸ“"
            all_content.append(f"=== ç¬¬{num}ç«  {status_icon} ({status}) ===\n\n{content}\n\n")

    return "\n".join(all_content)


def get_chapter_status(filepath, chapter_num):
    """è·å–ç« èŠ‚çŠ¶æ€ï¼šè‰ç¨¿æˆ–å·²å®šç¨¿"""
    if not filepath:
        return "æœªçŸ¥"

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å®šç¨¿çŠ¶æ€æ–‡ä»¶
    status_file = os.path.join(filepath, "chapter_status.json")
    if os.path.exists(status_file):
        try:
            with open(status_file, 'r', encoding='utf-8') as f:
                status_data = json.load(f)
            return status_data.get(str(chapter_num), "è‰ç¨¿")
        except:
            return "è‰ç¨¿"
    return "è‰ç¨¿"

def set_chapter_status(filepath, chapter_num, status):
    """è®¾ç½®ç« èŠ‚çŠ¶æ€"""
    if not filepath:
        return

    status_file = os.path.join(filepath, "chapter_status.json")
    status_data = {}

    # è¯»å–ç°æœ‰çŠ¶æ€
    if os.path.exists(status_file):
        try:
            with open(status_file, 'r', encoding='utf-8') as f:
                status_data = json.load(f)
        except:
            status_data = {}

    # æ›´æ–°çŠ¶æ€
    status_data[str(chapter_num)] = status

    # ä¿å­˜çŠ¶æ€
    try:
        with open(status_file, 'w', encoding='utf-8') as f:
            json.dump(status_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ä¿å­˜ç« èŠ‚çŠ¶æ€å¤±è´¥: {e}")

def get_chapter_list(filepath):
    """è·å–ç« èŠ‚åˆ—è¡¨ï¼ŒåŒ…å«çŠ¶æ€ä¿¡æ¯"""
    if not filepath:
        return []

    chapters_dir = os.path.join(filepath, "chapters")
    if not os.path.exists(chapters_dir):
        return []

    # è·å–æ‰€æœ‰ç« èŠ‚æ–‡ä»¶
    chapter_files = [f for f in os.listdir(chapters_dir) if f.startswith("chapter_") and f.endswith(".txt")]
    if not chapter_files:
        return []

    # æŒ‰ç« èŠ‚å·æ’åº
    chapter_numbers = []
    for f in chapter_files:
        try:
            num = int(f.replace("chapter_", "").replace(".txt", ""))
            chapter_numbers.append(num)
        except ValueError:
            continue

    chapter_numbers.sort()

    # æ·»åŠ çŠ¶æ€ä¿¡æ¯
    chapter_list = []
    for num in chapter_numbers:
        status = get_chapter_status(filepath, num)
        if status == "å·²å®šç¨¿":
            chapter_list.append(f"ç¬¬{num}ç«  âœ…")
        else:
            chapter_list.append(f"ç¬¬{num}ç«  ğŸ“")

    return chapter_list


def load_single_chapter(filepath, chapter_display_name):
    """åŠ è½½å•ä¸ªç« èŠ‚å†…å®¹"""
    if not filepath or not chapter_display_name:
        return ""

    # ä»æ˜¾ç¤ºåç§°æå–ç« èŠ‚å·ï¼ˆå¤„ç†å¸¦çŠ¶æ€çš„åç§°ï¼‰
    try:
        # ç§»é™¤çŠ¶æ€æ ‡è¯†ç¬¦
        clean_name = chapter_display_name.replace("âœ…", "").replace("ğŸ“", "").strip()
        chapter_num = int(clean_name.replace("ç¬¬", "").replace("ç« ", ""))
    except ValueError:
        return ""

    chapter_file = os.path.join(filepath, "chapters", f"chapter_{chapter_num}.txt")
    if not os.path.exists(chapter_file):
        return ""

    content = read_file(chapter_file)

    # åœ¨å†…å®¹å‰æ·»åŠ çŠ¶æ€ä¿¡æ¯
    status = get_chapter_status(filepath, chapter_num)
    status_info = f"ğŸ“Š ç« èŠ‚çŠ¶æ€: {status}\n" + "="*50 + "\n\n"

    return status_info + content


def handle_chapter_selection(filepath, selected_chapter):
    """å¤„ç†ç« èŠ‚é€‰æ‹©äº‹ä»¶"""
    content = load_single_chapter(filepath, selected_chapter)
    return content


def handle_prev_chapter(filepath, current_chapter):
    """å¤„ç†ä¸Šä¸€ç« æŒ‰é’®"""
    chapter_list = get_chapter_list(filepath)
    if not chapter_list or not current_chapter:
        return current_chapter, ""

    try:
        current_idx = chapter_list.index(current_chapter)
        if current_idx > 0:
            prev_chapter = chapter_list[current_idx - 1]
            content = load_single_chapter(filepath, prev_chapter)
            return prev_chapter, content
        else:
            return current_chapter, load_single_chapter(filepath, current_chapter)
    except ValueError:
        return current_chapter, ""


def handle_next_chapter(filepath, current_chapter):
    """å¤„ç†ä¸‹ä¸€ç« æŒ‰é’®"""
    chapter_list = get_chapter_list(filepath)
    if not chapter_list or not current_chapter:
        return current_chapter, ""

    try:
        current_idx = chapter_list.index(current_chapter)
        if current_idx < len(chapter_list) - 1:
            next_chapter = chapter_list[current_idx + 1]
            content = load_single_chapter(filepath, next_chapter)
            return next_chapter, content
        else:
            return current_chapter, load_single_chapter(filepath, current_chapter)
    except ValueError:
        return current_chapter, ""


def handle_refresh_chapters(filepath, current_chapter):
    """å¤„ç†åˆ·æ–°ç« èŠ‚åˆ—è¡¨"""
    chapter_list = get_chapter_list(filepath)

    # å¦‚æœå½“å‰é€‰æ‹©çš„ç« èŠ‚ä»ç„¶å­˜åœ¨ï¼Œä¿æŒé€‰æ‹©ï¼›å¦åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ª
    if current_chapter and current_chapter in chapter_list:
        selected = current_chapter
        content = load_single_chapter(filepath, selected)
    elif chapter_list:
        selected = chapter_list[0]
        content = load_single_chapter(filepath, selected)
    else:
        selected = None
        content = ""

    return gr.Dropdown(choices=chapter_list, value=selected), content

def handle_filepath_change(filepath):
    """å¤„ç†æ–‡ä»¶è·¯å¾„å˜åŒ–äº‹ä»¶"""
    status = check_file_status_and_init_ui(filepath)
    all_chapters = load_all_chapters(filepath)

    # è·å–ç« èŠ‚åˆ—è¡¨å¹¶è®¾ç½®é»˜è®¤é€‰æ‹©
    chapter_list = get_chapter_list(filepath)
    if chapter_list:
        selected_chapter = chapter_list[-1]  # é»˜è®¤é€‰æ‹©æœ€æ–°ç« èŠ‚
        single_chapter_content = load_single_chapter(filepath, selected_chapter)
    else:
        selected_chapter = None
        single_chapter_content = ""

    chapter_selector_update = gr.Dropdown(choices=chapter_list, value=selected_chapter)

    # åŠ è½½å°è¯´é…ç½®
    novel_params = {}
    if filepath and filepath.strip():
        novel_params = app.load_novel_config(filepath.strip())

    return (
        app.log_message(status['log_message']),  # log_output
        status['architecture_content'],          # architecture_content
        status['blueprint_content'],             # blueprint_content
        status['chapter_content'],               # chapter_content
        all_chapters,                            # all_chapters_content
        status['character_content'],             # character_content
        status['summary_content'],               # summary_content
        status['btn_step2_state'],               # btn_step2
        status['btn_step3_state'],               # btn_step3
        status['btn_step4_state'],               # btn_step4
        chapter_selector_update,                 # chapter_selector
        single_chapter_content,                  # single_chapter_content
        novel_params.get("topic", ""),           # topic_input
        novel_params.get("genre", "ç„å¹»"),       # genre_input
        novel_params.get("num_chapters", 10),    # num_chapters_input
        novel_params.get("word_number", 3000),   # word_number_input
        novel_params.get("user_guidance", ""),   # user_guidance_input
        novel_params.get("characters_involved", ""),  # characters_involved_input
        novel_params.get("key_items", ""),       # key_items_input
        novel_params.get("scene_location", ""),  # scene_location_input
        novel_params.get("time_constraint", "")  # time_constraint_input
    )

# åˆ é™¤é‡å¤çš„äº‹ä»¶å¤„ç†å™¨å‡½æ•°ï¼Œå·²ç»åœ¨create_interfaceä¸­ç›´æ¥è®¾ç½®

if __name__ == "__main__":
    demo = create_interface()

    print("ğŸš€ å¯åŠ¨AIå°è¯´ç”Ÿæˆå™¨Webç•Œé¢...")
    print("ğŸ“ è®¿é—®åœ°å€: http://localhost:7860")

    # è·å–ç«¯å£å·ï¼Œä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
    port = int(os.environ.get('GRADIO_SERVER_PORT', 7863))

    demo.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        show_error=True
    )